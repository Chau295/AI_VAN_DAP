[
        {
        "id": "Q1",
        "question": "Thế nào là dữ liệu không nhất quán (inconsistent data)? Làm thế nào để xử lý dữ liệu không nhất quán?",
        "sample_answer_text": "Dữ liệu không nhất quán là khi dữ liệu được ghi nhận khác nhau cho cùng một đối tượng/thực thể. Xử lý dữ liệu không nhất quán có thể bao gồm việc điều chỉnh các ràng buộc khóa ngoại, dữ liệu có thể không nhất quán do lỗi nhập liệu, lỗi hệ thống, hoặc do các biểu diễn dữ liệu không đồng nhất.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa dữ liệu không nhất quán",
                "text": "Định nghĩa dữ liệu không nhất quán: Dữ liệu không nhất quán là khi dữ liệu được ghi nhận khác nhau cho cùng một đối tượng/thực thể.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["ghi nhận khác nhau", "khác biệt", "không đồng nhất"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["cùng một đối tượng", "cùng thực thể"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Nguyên nhân không nhất quán",
                "text": "Nguyên nhân dẫn đến không nhất quán: do lỗi nhập liệu, lỗi hệ thống, hoặc biểu diễn dữ liệu không đồng nhất.",
                "weight": 2.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["lỗi nhập liệu", "lỗi hệ thống", "biểu diễn dữ liệu không đồng nhất"], "min_count": 2, "score_per_keyword": 1.0, "max_score_for_condition": 2.0, "partial_score_if_less": [{"count": 1, "score": 1.0}]}
                ]
            },
            {
                "id": "Cách xử lý không nhất quán",
                "text": "Cách xử lý dữ liệu không nhất quán: điều chỉnh các ràng buộc khóa ngoại, sửa chữa dữ liệu, hoặc đồng bộ hóa.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS_WITH_PARTIAL", "keywords": ["điều chỉnh ràng buộc khóa ngoại", "sửa chữa dữ liệu", "đồng bộ hóa"], "score_if_met": 3.0, "partial_score": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q2",
        "question": "Phân biệt giữa chuẩn hóa (normalization) và rời rạc hóa (discretization).",
        "sample_answer_text": "Chuẩn hóa (normalization) là quá trình biến đổi dữ liệu về một phạm vi nhỏ hơn, thường là [-1, 1]. Rời rạc hóa (discretization) là quá trình chuyển đổi các giá trị số thành các khoảng hoặc nhãn khái niệm.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Chuẩn hóa",
                "text": "Định nghĩa Chuẩn hóa (Normalization): biến đổi dữ liệu về một phạm vi nhỏ hơn, thường là [-1, 1] hoặc [0, 1].",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["biến đổi dữ liệu"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["phạm vi nhỏ hơn", "[-1, 1]", "[0, 1]"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Định nghĩa Rời rạc hóa",
                "text": "Định nghĩa Rời rạc hóa (Discretization): chuyển đổi các giá trị số thành các khoảng hoặc nhãn khái niệm.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chuyển đổi giá trị số"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["thành các khoảng", "nhãn khái niệm", "nhóm"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q3",
        "question": "Kể tên các phương pháp chuẩn hóa dữ liệu. Cho ví dụ về min-max normalization và z-score normalization.",
        "sample_answer_text": "Các phương pháp chuẩn hóa dữ liệu bao gồm: min-max normalization, z-score normalization, và normalization by decimal scaling. Ví dụ Min-max normalization: Giả sử giá trị min của thuộc tính A là 20, max là 100. Giá trị 60 sẽ được chuẩn hóa thành (60-20)/(100-20)=0.5. Ví dụ Z-score normalization: Giả sử giá trị trung bình của thuộc tính income là $54,000 và độ lệch chuẩn là $16,000. Giá trị $73,600 sẽ được chuẩn hóa thành (73600-54000)/16000=1.225.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Liệt kê phương pháp chuẩn hóa",
                "text": "Kể tên các phương pháp chuẩn hóa dữ liệu: min-max, z-score, decimal scaling.",
                "weight": 3.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["min-max", "z-score", "decimal scaling"], "min_count": 2, "score_per_keyword": 1.5, "max_score_for_condition": 3.0, "partial_score_if_less": [{"count": 1, "score": 1.5}]}
                ]
            },
            {
                "id": "Ví dụ Min-max",
                "text": "Ví dụ về Min-max normalization: công thức (giá trị - min) / (max - min) HOẶC phạm vi [0,1] HOẶC phạm vi [-1,1].",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS_WITH_PARTIAL", "keywords": ["min", "max", "công thức (giá trị - min) / (max - min)", "phạm vi [0,1]", "phạm vi [-1,1]"], "score_if_met": 3.5, "partial_score": 1.5}
                ]
            },
            {
                "id": "Ví dụ Z-score",
                "text": "Ví dụ về Z-score normalization: công thức (giá trị - trung bình) / độ lệch chuẩn.",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS_WITH_PARTIAL", "keywords": ["trung bình", "độ lệch chuẩn", "công thức (giá trị - trung bình) / độ lệch chuẩn"], "score_if_met": 3.5, "partial_score": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q4",
        "question": "Rời rạc hóa dữ liệu là gì? Kể tên một số phương pháp rời rạc hóa?",
        "sample_answer_text": "Rời rạc hóa dữ liệu là quá trình giảm số lượng giá trị của một thuộc tính liên tục bằng cách chia miền giá trị thành các khoảng và gán nhãn cho các khoảng này. Các phương pháp rời rạc hóa bao gồm: binning, cluster analysis,...",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Rời rạc hóa",
                "text": "Định nghĩa Rời rạc hóa dữ liệu: giảm số lượng giá trị hoặc chia miền giá trị thành các khoảng và gán nhãn khái niệm cho thuộc tính liên tục.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giảm số lượng giá trị", "chia miền giá trị", "khoảng"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["thuộc tính liên tục", "nhãn khái niệm"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            },
            {
                "id": "Liệt kê phương pháp rời rạc hóa",
                "text": "Kể tên các phương pháp rời rạc hóa: binning, cluster analysis.",
                "weight": 4.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["binning", "cluster analysis"], "min_count": 1, "score_per_keyword": 2.0, "max_score_for_condition": 4.0, "partial_score_if_less": [{"count": 1, "score": 2.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q5",
        "question": "Khi nào nên sử dụng min-max normalization? Khi nào nên sử dụng z-score normalization?",
        "sample_answer_text": "Min-max normalization thường được sử dụng khi muốn giữ nguyên mối quan hệ giữa các giá trị dữ liệu và khi biết trước giới hạn trên và dưới của dữ liệu. Z-score normalization thường được sử dụng khi dữ liệu có phân phối chuẩn hoặc gần chuẩn, và khi muốn loại bỏ ảnh hưởng của giá trị trung bình và độ lệch chuẩn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Sử dụng Min-max",
                "text": "Khi sử dụng Min-max normalization: giữ nguyên mối quan hệ giữa các giá trị dữ liệu và biết trước giới hạn trên và dưới của dữ liệu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giữ nguyên mối quan hệ"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["biết trước giới hạn", "giới hạn trên và dưới"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Sử dụng Z-score",
                "text": "Khi sử dụng Z-score normalization: dữ liệu có phân phối chuẩn hoặc gần chuẩn, và muốn loại bỏ ảnh hưởng của giá trị trung bình và độ lệch chuẩn.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["phân phối chuẩn", "gần chuẩn"], "score_if_met": 2.5},
                    {"type": "AND_KEYWORDS", "keywords": ["loại bỏ ảnh hưởng", "trung bình", "độ lệch chuẩn"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25}
                ]
            }
        ]
    },
    {
        "id": "Q6",
        "question": "Mục đích của việc giảm số chiều dữ liệu là gì?",
        "sample_answer_text": "Mục đích của việc giảm số chiều dữ liệu là để giảm số lượng biến hoặc thuộc tính được xem xét, giúp giảm độ phức tạp của mô hình, cải thiện hiệu suất tính toán và loại bỏ các thuộc tính không liên quan hoặc dư thừa. Giảm chiều cũng giúp tránh hiện tượng overfitting và làm cho dữ liệu dễ hình dung hơn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Giảm biến/thuộc tính",
                "text": "Giảm số lượng biến/thuộc tính.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giảm số lượng biến", "giảm thuộc tính", "ít thuộc tính hơn"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Giảm độ phức tạp mô hình",
                "text": "Giảm độ phức tạp của mô hình.",
                "weight": 2.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giảm độ phức tạp", "đơn giản hóa mô hình"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Cải thiện hiệu suất tính toán",
                "text": "Cải thiện hiệu suất tính toán.",
                "weight": 2.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["cải thiện hiệu suất", "tăng tốc độ tính toán", "tiết kiệm thời gian"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Loại bỏ thuộc tính dư thừa",
                "text": "Loại bỏ thuộc tính không liên quan/dư thừa.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["loại bỏ thuộc tính không liên quan", "loại bỏ thuộc tính dư thừa", "giảm nhiễu"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q7",
        "question": "Giải thích về khái niệm outlier. Làm thế nào để phát hiện và xử lý outlier?",
        "sample_answer_text": "Outlier là những điểm dữ liệu không tuân theo đặc tính/hành vi chung của tập dữ liệu. Outlier có thể được phát hiện bằng các phương pháp thống kê (ví dụ: dựa trên phân phối, khoảng cách, mật độ, độ lệch), boxplot, clustering, hoặc IQR. Xử lý outlier có thể bằng cách loại bỏ hoặc điều chỉnh giá trị.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Outlier",
                "text": "Định nghĩa Outlier: điểm dữ liệu không tuân theo đặc tính/hành vi chung của tập dữ liệu.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không tuân theo đặc tính", "khác biệt bất thường", "ngoại lai"], "score_if_met": 4.0}
                ]
            },
            {
                "id": "Cách phát hiện Outlier",
                "text": "Cách phát hiện Outlier: phương pháp thống kê, boxplot, clustering, hoặc IQR.",
                "weight": 3.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["phương pháp thống kê", "boxplot", "clustering", "IQR"], "min_count": 2, "score_per_keyword": 1.5, "max_score_for_condition": 3.0, "partial_score_if_less": [{"count": 1, "score": 1.5}]}
                ]
            },
            {
                "id": "Cách xử lý Outlier",
                "text": "Cách xử lý Outlier: loại bỏ hoặc điều chỉnh giá trị.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS_WITH_PARTIAL", "keywords": ["loại bỏ", "điều chỉnh giá trị", "thay thế"], "score_if_met": 3.0, "partial_score": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q8",
        "question": "Xây dựng thuộc tính (feature construction) là gì? Tại sao cần xây dựng thuộc tính?",
        "sample_answer_text": "Xây dựng thuộc tính là quá trình tạo ra các thuộc tính mới từ các thuộc tính hiện có. Cần xây dựng thuộc tính để hỗ trợ kiểm tra tính chính xác, giúp hiểu cấu trúc dữ liệu đa chiều và phát hiện thông tin thiếu sót về mối quan hệ giữa các thuộc tính.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Xây dựng thuộc tính",
                "text": "Định nghĩa Xây dựng thuộc tính: tạo ra các thuộc tính mới từ các thuộc tính hiện có.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tạo ra thuộc tính mới", "tạo biến mới"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["từ thuộc tính hiện có", "kết hợp thuộc tính"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Lý do cần xây dựng thuộc tính",
                "text": "Lý do cần xây dựng thuộc tính: hỗ trợ kiểm tra tính chính xác, giúp hiểu cấu trúc dữ liệu đa chiều và phát hiện thông tin thiếu sót về mối quan hệ giữa các thuộc tính.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["kiểm tra tính chính xác", "hiểu cấu trúc dữ liệu", "phát hiện thông tin thiếu sót"], "min_count": 2, "score_per_keyword": 2.5, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 1, "score": 2.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q9",
        "question": "Biến đổi dữ liệu (data transformation) là gì? Cho ví dụ về các phương pháp biến đổi dữ liệu.",
        "sample_answer_text": "Biến đổi dữ liệu là quá trình biến đổi hoặc kết hợp dữ liệu vào những dạng phù hợp cho phân tích và khai phá dữ liệu. Các phương pháp biến đổi dữ liệu bao gồm: chuẩn hóa, rời rạc hóa, làm trơn dữ liệu, và xây dựng thuộc tính.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Biến đổi dữ liệu",
                "text": "Định nghĩa Biến đổi dữ liệu: biến đổi hoặc kết hợp dữ liệu vào những dạng phù hợp cho phân tích và khai phá dữ liệu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["biến đổi dữ liệu", "kết hợp dữ liệu"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["phù hợp cho phân tích", "khai phá dữ liệu"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Các phương pháp biến đổi dữ liệu",
                "text": "Các phương pháp biến đổi dữ liệu: chuẩn hóa, rời rạc hóa, làm trơn dữ liệu, và xây dựng thuộc tính.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["chuẩn hóa", "rời rạc hóa", "làm trơn dữ liệu", "xây dựng thuộc tính"], "min_count": 3, "score_per_keyword": 1.66, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 2, "score": 3.0}, {"count": 1, "score": 1.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q10",
        "question": "Làm sạch dữ liệu (data cleaning) bao gồm những công việc gì?",
        "sample_answer_text": "Làm sạch dữ liệu bao gồm các công việc: điền vào các giá trị bị thiếu, làm trơn dữ liệu nhiễu, xác định và loại bỏ các outlier, và giải quyết các dữ liệu không nhất quán.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các công việc Data Cleaning",
                "text": "Các công việc chính của Data Cleaning: điền vào các giá trị bị thiếu, làm trơn dữ liệu nhiễu, xác định và loại bỏ các outlier, và giải quyết các dữ liệu không nhất quán.",
                "weight": 10.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["điền giá trị bị thiếu", "làm trơn dữ liệu nhiễu", "xác định và loại bỏ outlier", "giải quyết dữ liệu không nhất quán"], "min_count": 3, "score_per_keyword": 3.33, "max_score_for_condition": 10.0, "partial_score_if_less": [{"count": 2, "score": 6.0}, {"count": 1, "score": 3.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q11",
        "question": "Tích hợp dữ liệu (data integration) là gì?",
        "sample_answer_text": "Tích hợp dữ liệu là quá trình kết hợp dữ liệu từ nhiều nguồn khác nhau vào một kho dữ liệu thống nhất.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Tích hợp dữ liệu",
                "text": "Định nghĩa Tích hợp dữ liệu: quá trình kết hợp dữ liệu từ nhiều nguồn khác nhau vào một kho dữ liệu thống nhất.",
                "weight": 10.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["kết hợp dữ liệu", "nhiều nguồn"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["kho dữ liệu thống nhất", "một hệ thống chung", "tổng hợp dữ liệu"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q12",
        "question": "Giảm dữ liệu (data reduction) là gì? Kể tên các kỹ thuật giảm dữ liệu.",
        "sample_answer_text": "Giảm dữ liệu là quá trình giảm kích thước dữ liệu bằng cách kết hợp dữ liệu, loại bỏ thuộc tính dư thừa, hoặc gom cụm dữ liệu. Các kỹ thuật giảm dữ liệu bao gồm: dimensionality reduction (giảm chiều), numerosity reduction (giảm số lượng), data compression (nén dữ liệu), wavelet transforms, principal components analysis và sampling.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Giảm dữ liệu",
                "text": "Định nghĩa Giảm dữ liệu: giảm kích thước dữ liệu bằng cách kết hợp dữ liệu, loại bỏ thuộc tính dư thừa, hoặc gom cụm dữ liệu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giảm kích thước dữ liệu", "thu nhỏ dữ liệu"], "score_if_met": 2.5},
                    {"type": "COUNT_KEYWORDS", "keywords": ["kết hợp dữ liệu", "loại bỏ thuộc tính dư thừa", "gom cụm dữ liệu"], "min_count": 2, "score_per_keyword": 1.25, "max_score_for_condition": 2.5, "partial_score_if_less": [{"count": 1, "score": 1.0}]}
                ]
            },
            {
                "id": "Kỹ thuật giảm dữ liệu",
                "text": "Kể tên các kỹ thuật giảm dữ liệu: dimensionality reduction, numerosity reduction, data compression, wavelet transforms, principal components analysis, sampling.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["dimensionality reduction", "numerosity reduction", "data compression", "wavelet transforms", "principal components analysis", "sampling"], "min_count": 3, "score_per_keyword": 1.66, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 2, "score": 3.0}, {"count": 1, "score": 1.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q13",
        "question": "Phân biệt giữa feature selection và feature extraction.",
        "sample_answer_text": "Feature selection (lựa chọn thuộc tính) là quá trình chọn một tập hợp con các thuộc tính gốc. Feature extraction (trích chọn thuộc tính) là quá trình biến đổi dữ liệu để tạo ra các thuộc tính mới.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Feature Selection",
                "text": "Định nghĩa Feature Selection: chọn một tập hợp con các thuộc tính gốc.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chọn tập con", "thuộc tính gốc"], "score_if_met": 5.0}
                ]
            },
            {
                "id": "Định nghĩa Feature Extraction",
                "text": "Định nghĩa Feature Extraction: biến đổi dữ liệu để tạo ra các thuộc tính mới.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["biến đổi dữ liệu", "tạo ra thuộc tính mới"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q14",
        "question": "Tại sao cần làm sạch dữ liệu trước khi phân tích?",
        "sample_answer_text": "Cần làm sạch dữ liệu trước khi phân tích vì dữ liệu thực tế thường không hoàn chỉnh, nhiễu và không nhất quán. Dữ liệu \"bẩn\" có thể gây ra sự nhầm lẫn trong quá trình khai thác và dẫn đến kết quả không đáng tin cậy.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Lý do dữ liệu bẩn",
                "text": "Lý do dữ liệu \"bẩn\": không hoàn chỉnh, nhiễu và không nhất quán.",
                "weight": 6.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["không hoàn chỉnh", "nhiễu", "không nhất quán"], "min_count": 2, "score_per_keyword": 3.0, "max_score_for_condition": 6.0, "partial_score_if_less": [{"count": 1, "score": 3.0}]}
                ]
            },
            {
                "id": "Ảnh hưởng dữ liệu bẩn",
                "text": "Ảnh hưởng của dữ liệu \"bẩn\": gây ra sự nhầm lẫn hoặc kết quả không đáng tin cậy.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["nhầm lẫn", "không đáng tin cậy", "sai lệch"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q15",
        "question": "Cho ví dụ về trường hợp cần tích hợp dữ liệu.",
        "sample_answer_text": "Một ví dụ về trường hợp cần tích hợp dữ liệu là khi một công ty có dữ liệu khách hàng từ nhiều nguồn khác nhau như hệ thống CRM, trang web và mạng xã hội. Để có cái nhìn toàn diện về khách hàng, công ty cần tích hợp dữ liệu từ các nguồn này lại với nhau.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Tình huống tích hợp dữ liệu",
                "text": "Nêu được tình huống cần tích hợp: có dữ liệu từ nhiều nguồn khác nhau (CRM, website, mạng xã hội).",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["nhiều nguồn khác nhau", "đa nguồn", "crm", "website", "mạng xã hội"], "score_if_met": 6.0}
                ]
            },
            {
                "id": "Mục đích tích hợp dữ liệu",
                "text": "Mục đích của việc tích hợp trong ví dụ: có cái nhìn toàn diện về khách hàng hoặc tổng hợp thông tin.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["cái nhìn toàn diện", "tổng hợp thông tin", "hiểu khách hàng hơn"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q16",
        "question": "Tại sao cần giảm số chiều dữ liệu?",
        "sample_answer_text": "Cần giảm số chiều dữ liệu để giảm độ phức tạp của mô hình, cải thiện hiệu suất tính toán và loại bỏ các thuộc tính không liên quan hoặc dư thừa. Giảm chiều cũng giúp tránh hiện tượng overfitting và làm cho dữ liệu dễ hình dung hơn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Lý do chính giảm chiều",
                "text": "Các lý do chính: giảm độ phức tạp của mô hình, cải thiện hiệu suất tính toán, loại bỏ thuộc tính không liên quan hoặc dư thừa.",
                "weight": 6.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["giảm độ phức tạp", "cải thiện hiệu suất tính toán", "loại bỏ thuộc tính không liên quan", "dư thừa"], "min_count": 2, "score_per_keyword": 3.0, "max_score_for_condition": 6.0, "partial_score_if_less": [{"count": 1, "score": 3.0}]}
                ]
            },
            {
                "id": "Lợi ích bổ sung giảm chiều",
                "text": "Các lợi ích bổ sung: tránh hiện tượng overfitting và làm cho dữ liệu dễ hình dung hơn.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tránh overfitting", "dễ hình dung"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q17",
        "question": "Định nghĩa giả thuyết không (H0) và giả thuyết đối (H1).",
        "sample_answer_text": "Giả thuyết không (H0) là một phát biểu mặc định về một tham số của quần thể mà ta muốn kiểm định. Giả thuyết đối (H1) là một phát biểu mâu thuẫn với giả thuyết không, mà ta sẽ chấp nhận nếu có đủ bằng chứng bác bỏ H0. Ví dụ: H0 có thể là \"trung bình số TV trong các hộ gia đình ở Mỹ là ít nhất 3\", và H1 là \"trung bình số TV nhỏ hơn 3\". H0 thường bao gồm các dấu =, ≥, ≤ còn H1 sẽ có các dấu ≠, <, >.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa H0",
                "text": "Định nghĩa Giả thuyết không (H0): phát biểu mặc định về một tham số của quần thể.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["phát biểu mặc định", "tham số quần thể"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            },
            {
                "id": "Định nghĩa H1",
                "text": "Định nghĩa Giả thuyết đối (H1): phát biểu mâu thuẫn với H0 và chấp nhận nếu có đủ bằng chứng bác bỏ H0.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["mâu thuẫn với h0", "chấp nhận nếu bác bỏ h0"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            },
            {
                "id": "Đặc điểm dấu so sánh",
                "text": "Đặc điểm dấu so sánh: H0 có =, ≥, ≤; H1 có ≠, <, >.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["h0 có dấu bằng", "h1 có dấu khác/lớn hơn/nhỏ hơn", "h0 có dấu =", "h0 có dấu lớn hơn bằng", "h0 có dấu nhỏ hơn bằng", "h1 có dấu khác", "h1 có dấu nhỏ hơn", "h1 có dấu lớn hơn"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q18",
        "question": "Mức ý nghĩa (alpha) là gì? Vai trò của mức ý nghĩa trong kiểm định giả thuyết.",
        "sample_answer_text": "Mức ý nghĩa (alpha, α) là xác suất mà ta chấp nhận mắc lỗi loại I, tức là bác bỏ giả thuyết không (H0) khi nó thực sự đúng. Mức ý nghĩa thường được chọn là 0.05 (5%), có nghĩa là có 5% cơ hội ta sẽ bác bỏ H0 sai.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa mức ý nghĩa",
                "text": "Định nghĩa Mức ý nghĩa: xác suất mắc lỗi loại I.",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["xác suất", "lỗi loại i"], "score_if_met": 6.0, "partial_score_per_keyword": 3.0}
                ]
            },
            {
                "id": "Ý nghĩa chọn Alpha",
                "text": "Ý nghĩa của việc chọn Alpha: ví dụ về α = 0.05 và ý nghĩa của nó (5% cơ hội ta sẽ bác bỏ H0 sai).",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["0.05", "5%", "bác bỏ h0 sai"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q19",
        "question": "Phân biệt kiểm định một phía và kiểm định hai phía.",
        "sample_answer_text": "Kiểm định một phía (one-tailed test) được sử dụng khi giả thuyết đối (H1) chỉ ra một hướng cụ thể của sự khác biệt (lớn hơn hoặc nhỏ hơn). Kiểm định hai phía (two-tailed test) được sử dụng khi H1 chỉ ra rằng có sự khác biệt nhưng không chỉ rõ hướng của nó (khác biệt).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Kiểm định một phía",
                "text": "Định nghĩa Kiểm định một phía: H1 chỉ ra một hướng cụ thể của sự khác biệt (lớn hơn hoặc nhỏ hơn).",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["một hướng cụ thể", "lớn hơn", "nhỏ hơn"], "score_if_met": 5.0}
                ]
            },
            {
                "id": "Kiểm định hai phía",
                "text": "Định nghĩa Kiểm định hai phía: H1 chỉ ra rằng có sự khác biệt nhưng không chỉ rõ hướng của nó (khác biệt).",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không chỉ rõ hướng", "khác biệt", "hai phía"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q20",
        "question": "Giá trị p (p-value) là gì? Cách sử dụng p-value để đưa ra quyết định trong kiểm định giả thuyết.",
        "sample_answer_text": "Giá trị p-value là xác suất quan sát được một kết quả kiểm định (test statistic) cực đoan hoặc hơn, giả định rằng H0 là đúng. Nếu p-value nhỏ hơn hoặc bằng mức ý nghĩa (α), ta bác bỏ H0. Ngược lại, nếu p-value lớn hơn α, ta không bác bỏ H0.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa p-value",
                "text": "Định nghĩa p-value: xác suất quan sát được một kết quả kiểm định cực đoan hoặc hơn, giả định rằng H0 là đúng.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["xác suất", "kết quả cực đoan", "h0 đúng"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5}
                ]
            },
            {
                "id": "Cách sử dụng p-value",
                "text": "Cách sử dụng p-value để ra quyết định: Nếu p-value ≤ α, bác bỏ H0; Nếu p-value > α, không bác bỏ H0.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["p-value nhỏ hơn alpha", "bác bỏ h0"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "AND_KEYWORDS", "keywords": ["p-value lớn hơn alpha", "không bác bỏ h0"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25}
                ]
            }
        ]
    },
    {
        "id": "Q21",
        "question": "Thế nào là miền bác bỏ (rejection region)?",
        "sample_answer_text": "Miền bác bỏ (rejection region) là tập hợp các giá trị của thống kê kiểm định (test statistic) mà nếu giá trị thống kê rơi vào miền này, ta sẽ bác bỏ H0. Miền bác bỏ được xác định dựa trên mức ý nghĩa (α) và loại kiểm định (một phía hay hai phía).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Miền bác bỏ",
                "text": "Định nghĩa Miền bác bỏ: tập hợp các giá trị của thống kê kiểm định mà nếu giá trị thống kê rơi vào miền này, ta sẽ bác bỏ H0.",
                "weight": 7.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tập hợp giá trị", "thống kê kiểm định"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75},
                    {"type": "AND_KEYWORDS", "keywords": ["rơi vào miền này", "bác bỏ h0"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75}
                ]
            },
            {
                "id": "Cách xác định Miền bác bỏ",
                "text": "Cách xác định Miền bác bỏ: dựa trên mức ý nghĩa (α) và loại kiểm định.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["mức ý nghĩa", "loại kiểm định"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q22",
        "question": "Giá trị tới hạn (critical value) là gì? Cách sử dụng giá trị tới hạn để đưa ra quyết định trong kiểm định giả thuyết.",
        "sample_answer_text": "Giá trị tới hạn (critical value) là giá trị phân tách miền bác bỏ và miền không bác bỏ trong phân phối của thống kê kiểm định. Nếu giá trị thống kê kiểm định vượt quá giá trị tới hạn (trong miền bác bỏ), ta sẽ bác bỏ H0.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Giá trị tới hạn",
                "text": "Định nghĩa Giá trị tới hạn: giá trị phân tách miền bác bỏ và miền không bác bỏ.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["giá trị phân tách", "miền bác bỏ", "miền không bác bỏ"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            },
            {
                "id": "Cách sử dụng Giá trị tới hạn",
                "text": "Cách sử dụng giá trị tới hạn để ra quyết định: Nếu giá trị thống kê kiểm định vượt quá giá trị tới hạn (trong miền bác bỏ), ta sẽ bác bỏ H0.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["thống kê kiểm định vượt quá", "rơi vào miền bác bỏ", "bác bỏ h0"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            }
        ]
    },
    {
        "id": "Q23",
        "question": "Lỗi loại I và lỗi loại II.",
        "sample_answer_text": "Lỗi loại I (Type I error) xảy ra khi ta bác bỏ H0 khi nó thực sự đúng (false positive). Xác suất mắc lỗi loại I chính là mức ý nghĩa α. Lỗi loại II (Type II error) xảy ra khi ta không bác bỏ H0 khi nó thực sự sai (false negative).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Lỗi loại I",
                "text": "Định nghĩa Lỗi loại I: bác bỏ H0 khi nó thực sự đúng (false positive). Xác suất mắc lỗi loại I chính là mức ý nghĩa α.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["bác bỏ h0", "h0 đúng", "false positive"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["xác suất", "mức ý nghĩa alpha"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Định nghĩa Lỗi loại II",
                "text": "Định nghĩa Lỗi loại II: không bác bỏ H0 khi nó thực sự sai (false negative).",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không bác bỏ h0", "h0 sai", "false negative"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q24",
        "question": "Khi nào sử dụng Z-test? Công thức tính thống kê Z.",
        "sample_answer_text": "Z-test được sử dụng khi kiểm định giả thuyết về trung bình của quần thể khi độ lệch chuẩn của quần thể đã biết (σ), hoặc khi cỡ mẫu lớn (n>30). Công thức tính thống kê Z: Z= (X̄ - μ) / (σ / √n), trong đó: Xˉ là trung bình mẫu, μ là trung bình quần thể, σ là độ lệch chuẩn quần thể, và n là cỡ mẫu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Sử dụng Z-test",
                "text": "Khi sử dụng Z-test: kiểm định giả thuyết về trung bình của quần thể khi độ lệch chuẩn của quần thể đã biết (σ) hoặc khi cỡ mẫu lớn (n>30).",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["kiểm định trung bình", "quần thể"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "OR_KEYWORDS", "keywords": ["độ lệch chuẩn quần thể đã biết", "sigma đã biết"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["cỡ mẫu lớn", "n > 30"], "score_if_met": 1.5}
                ]
            },
            {
                "id": "Công thức Z-statistic",
                "text": "Công thức tính thống kê Z: Z= (X̄ - μ) / (σ / √n), với X̄ là trung bình mẫu, μ là trung bình quần thể, σ là độ lệch chuẩn quần thể, và n là cỡ mẫu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "FORMULA", "formula_keywords": ["x̄", "μ", "σ", "√n", "/"], "score_if_met": 3.0},
                    {"type": "COUNT_KEYWORDS", "keywords": ["trung bình mẫu", "trung bình quần thể", "độ lệch chuẩn quần thể", "cỡ mẫu"], "min_count": 3, "score_per_keyword": 0.66, "max_score_for_condition": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q25",
        "question": "Khi nào sử dụng T-test? Công thức tính thống kê T.",
        "sample_answer_text": "T-test được sử dụng khi kiểm định giả thuyết về trung bình của quần thể khi độ lệch chuẩn của quần thể chưa biết và cỡ mẫu nhỏ (n < 30). Công thức tính thống kê T: t = (X̄ - μ) /(s / √n), trong đó: Xˉ là trung bình mẫu, μ là trung bình quần thể, s là độ lệch chuẩn mẫu và n là cỡ mẫu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Sử dụng T-test",
                "text": "Khi sử dụng T-test: kiểm định giả thuyết về trung bình của quần thể khi độ lệch chuẩn của quần thể chưa biết và cỡ mẫu nhỏ (n < 30).",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["kiểm định trung bình", "quần thể"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "OR_KEYWORDS", "keywords": ["độ lệch chuẩn quần thể chưa biết", "sigma chưa biết"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["cỡ mẫu nhỏ", "n < 30"], "score_if_met": 1.5}
                ]
            },
            {
                "id": "Công thức T-statistic",
                "text": "Công thức tính thống kê T: t = (X̄ - μ) /(s / √n), với X̄ là trung bình mẫu, μ là trung bình quần thể, s là độ lệch chuẩn mẫu và n là cỡ mẫu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "FORMULA", "formula_keywords": ["x̄", "μ", "s", "√n", "/"], "score_if_met": 3.0},
                    {"type": "COUNT_KEYWORDS", "keywords": ["trung bình mẫu", "trung bình quần thể", "độ lệch chuẩn mẫu", "cỡ mẫu"], "min_count": 3, "score_per_keyword": 0.66, "max_score_for_condition": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q26",
        "question": "Khi nào sử dụng F-test? Công thức tính thống kê F.",
        "sample_answer_text": "F-test thường được sử dụng trong phân tích phương sai (ANOVA) để kiểm định sự khác biệt giữa các trung bình của nhiều nhóm. Công thức tính thống kê F: F=MSA/MSW, trong đó: MSA là phương sai giữa các nhóm (Mean Square Among), MSW là phương sai trong các nhóm (Mean Square Within).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Sử dụng F-test",
                "text": "Khi sử dụng F-test: trong phân tích phương sai (ANOVA) để kiểm định sự khác biệt giữa các trung bình của nhiều nhóm.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["anova", "phân tích phương sai"], "score_if_met": 2.5},
                    {"type": "AND_KEYWORDS", "keywords": ["kiểm định khác biệt", "nhiều nhóm", "trung bình"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25}
                ]
            },
            {
                "id": "Công thức F-statistic",
                "text": "Công thức tính thống kê F: F=MSA/MSW, với MSA là phương sai giữa các nhóm, MSW là phương sai trong các nhóm.",
                "weight": 5.0,
                "conditions": [
                    {"type": "FORMULA", "formula_keywords": ["msa", "msw", "/"], "score_if_met": 3.0},
                    {"type": "COUNT_KEYWORDS", "keywords": ["phương sai giữa các nhóm", "phương sai trong các nhóm"], "min_count": 1, "score_per_keyword": 2.0, "max_score_for_condition": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q27",
        "question": "Giải thích về Central Limit Theorem.",
        "sample_answer_text": "Định lý giới hạn trung tâm (Central Limit Theorem - CLT) phát biểu rằng phân phối của trung bình mẫu sẽ xấp xỉ phân phối chuẩn khi cỡ mẫu đủ lớn (thường n>30), bất kể phân phối của quần thể gốc như thế nào. CLT rất quan trọng vì nó cho phép chúng ta sử dụng các phương pháp thống kê dựa trên phân phối chuẩn ngay cả khi dữ liệu gốc không có phân phối chuẩn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa CLT",
                "text": "Định nghĩa CLT: phân phối của trung bình mẫu sẽ xấp xấp phân phối chuẩn khi cỡ mẫu đủ lớn (thường n>30), bất kể phân phối của quần thể gốc như thế nào.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["phân phối trung bình mẫu"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["xấp xỉ phân phối chuẩn", "có dạng chuông"], "score_if_met": 2.5},
                    {"type": "AND_KEYWORDS", "keywords": ["cỡ mẫu đủ lớn", "n > 30", "bất kể phân phối quần thể gốc"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Tầm quan trọng của CLT",
                "text": "Tầm quan trọng của CLT: cho phép sử dụng các phương pháp thống kê dựa trên phân phối chuẩn ngay cả khi dữ liệu gốc không có phân phối chuẩn.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["sử dụng phương pháp thống kê dựa trên phân phối chuẩn", "dữ liệu gốc không chuẩn"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q28",
        "question": "Phân biệt giữa population và sample.",
        "sample_answer_text": "Population (quần thể) là toàn bộ tập hợp các đối tượng hoặc các phần tử mà ta quan tâm. Sample (mẫu) là một tập con của quần thể được chọn để phân tích.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Population",
                "text": "Định nghĩa Population: toàn bộ tập hợp các đối tượng hoặc phần tử mà ta quan tâm.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["toàn bộ tập hợp", "quan tâm"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5}
                ]
            },
            {
                "id": "Định nghĩa Sample",
                "text": "Định nghĩa Sample: tập con của quần thể được chọn để phân tích.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tập con", "quần thể", "chọn để phân tích"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            }
        ]
    },
    {
        "id": "Q29",
        "question": "Thống kê mô tả là gì? Kể tên một số thống kê mô tả cơ bản.",
        "sample_answer_text": "Thống kê mô tả (descriptive statistics) là các phương pháp tóm tắt và mô tả các đặc điểm chính của dữ liệu. Một số thống kê mô tả cơ bản bao gồm: Trung bình (mean), trung vị (median), mode, phương sai (variance), độ lệch chuẩn (standard deviation), khoảng biến thiên (range), tứ phân vị (quartiles), IQR.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Thống kê mô tả",
                "text": "Định nghĩa Thống kê mô tả: các phương pháp tóm tắt và mô tả các đặc điểm chính của dữ liệu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tóm tắt", "mô tả", "đặc điểm chính của dữ liệu"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            },
            {
                "id": "Thống kê mô tả cơ bản",
                "text": "Kể tên một số thống kê mô tả cơ bản: Trung bình, trung vị, mode, phương sai, độ lệch chuẩn, khoảng biến thiên, tứ phân vị, IQR.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["trung bình", "trung vị", "mode", "phương sai", "độ lệch chuẩn", "khoảng biến thiên", "tứ phân vị", "iqr"], "min_count": 3, "score_per_keyword": 1.66, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 2, "score": 3.0}, {"count": 1, "score": 1.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q30",
        "question": "Độ lệch chuẩn (standard deviation) là gì? Ý nghĩa của độ lệch chuẩn.",
        "sample_answer_text": "Độ lệch chuẩn (standard deviation) là thước đo sự phân tán của dữ liệu xung quanh giá trị trung bình. Độ lệch chuẩn càng lớn, dữ liệu càng phân tán.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Độ lệch chuẩn",
                "text": "Định nghĩa Độ lệch chuẩn: thước đo sự phân tán của dữ liệu xung quanh giá trị trung bình.",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["thước đo phân tán", "xung quanh trung bình"], "score_if_met": 6.0, "partial_score_per_keyword": 3.0}
                ]
            },
            {
                "id": "Ý nghĩa Độ lệch chuẩn",
                "text": "Ý nghĩa của Độ lệch chuẩn: Độ lệch chuẩn càng lớn, dữ liệu càng phân tán.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["lớn hơn", "phân tán hơn"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q31",
        "question": "Phương sai (variance) là gì? Mối quan hệ giữa phương sai và độ lệch chuẩn.",
        "sample_answer_text": "Phương sai (variance) là trung bình của bình phương các độ lệch của mỗi giá trị dữ liệu so với trung bình. Độ lệch chuẩn là căn bậc hai của phương sai.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Phương sai",
                "text": "Định nghĩa Phương sai: trung bình của bình phương các độ lệch của mỗi giá trị dữ liệu so với trung bình.",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["trung bình", "bình phương độ lệch"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["so với trung bình"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Mối quan hệ Phương sai và Độ lệch chuẩn",
                "text": "Mối quan hệ giữa Phương sai và Độ lệch chuẩn: Độ lệch chuẩn là căn bậc hai của phương sai.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["căn bậc hai", "phương sai"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q32",
        "question": "Phân phối chuẩn (normal distribution) là gì? Đặc điểm của phân phối chuẩn.",
        "sample_answer_text": "Phân phối chuẩn (normal distribution) là một phân phối xác suất đối xứng, hình chuông. Các đặc điểm của phân phối chuẩn: Trung bình, trung vị và mode trùng nhau, đối xứng qua trung bình, và có 68% dữ liệu nằm trong khoảng một độ lệch chuẩn so với trung bình, 95% trong hai độ lệch chuẩn, và gần như toàn bộ trong ba độ lệch chuẩn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Phân phối chuẩn",
                "text": "Định nghĩa Phân phối chuẩn: một phân phối xác suất đối xứng, hình chuông.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["phân phối xác suất", "đối xứng", "hình chuông"], "score_if_met": 4.0, "partial_score_per_keyword": 1.33}
                ]
            },
            {
                "id": "Đặc điểm Phân phối chuẩn",
                "text": "Đặc điểm của Phân phối chuẩn: Trung bình, trung vị và mode trùng nhau, đối xứng qua trung bình, và có 68% dữ liệu nằm trong khoảng một độ lệch chuẩn so với trung bình, 95% trong hai độ lệch chuẩn, và gần như toàn bộ trong ba độ lệch chuẩn.",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["trung bình, trung vị, mode trùng nhau", "đối xứng qua trung bình"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["68%", "95%", "hai độ lệch chuẩn"], "score_if_met": 3.0}
                ]
            }
        ]
    },
    {
        "id": "Q33",
        "question": "Thế nào là kiểm định giả thuyết về trung bình tổng thể?",
        "sample_answer_text": "Kiểm định giả thuyết về trung bình tổng thể là quá trình kiểm định xem giá trị trung bình của một biến số trong quần thể có khác biệt đáng kể so với một giá trị cụ thể hay không.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Kiểm định trung bình tổng thể",
                "text": "Định nghĩa Kiểm định giả thuyết về trung bình tổng thể: quá trình kiểm định xem giá trị trung bình của một biến số trong quần thể có khác biệt đáng kể so với một giá trị cụ thể hay không.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["kiểm định", "đánh giá"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["trung bình", "quần thể"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["khác biệt đáng kể", "khác với giá trị cụ thể"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q34",
        "question": "Thế nào là kiểm định giả thuyết về phương sai tổng thể?",
        "sample_answer_text": "Kiểm định giả thuyết về phương sai tổng thể là quá trình kiểm định xem phương sai của một biến số trong quần thể có khác biệt đáng kể so với một giá trị cụ thể hay không.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Kiểm định phương sai tổng thể",
                "text": "Định nghĩa Kiểm định giả thuyết về phương sai tổng thể: quá trình kiểm định xem phương sai của một biến số trong quần thể có khác biệt đáng kể so với một giá trị cụ thể hay không.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["kiểm định", "đánh giá"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["phương sai", "quần thể"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["khác biệt đáng kể", "khác với giá trị cụ thể"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q35",
        "question": "Thế nào là kiểm định giả thuyết về sự khác biệt giữa hai trung bình tổng thể?",
        "sample_answer_text": "Kiểm định giả thuyết về sự khác biệt giữa hai trung bình tổng thể là quá trình kiểm định xem có sự khác biệt đáng kể về trung bình của một biến số giữa hai quần thể hay không. Có thể sử dụng t-test hoặc z-test cho việc này tùy thuộc vào điều kiện.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Kiểm định hai trung bình",
                "text": "Định nghĩa Kiểm định giả thuyết về sự khác biệt giữa hai trung bình tổng thể: quá trình kiểm định xem có sự khác biệt đáng kể về trung bình của một biến số giữa hai quần thể hay không.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["kiểm định", "đánh giá"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["khác biệt đáng kể", "trung bình"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "OR_KEYWORDS", "keywords": ["hai quần thể", "giữa hai nhóm"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Các test cho hai trung bình",
                "text": "Các test có thể sử dụng: t-test hoặc z-test.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["t-test", "z-test"], "score_if_met": 3.0}
                ]
            }
        ]
    },
    {
        "id": "Q36",
        "question": "Thế nào là ANOVA?",
        "sample_answer_text": "ANOVA (Analysis of Variance - Phân tích phương sai) là một phương pháp thống kê được sử dụng để kiểm định sự khác biệt giữa trung bình của nhiều nhóm. ANOVA chia tổng phương sai thành các phần có thể quy cho các nguồn khác nhau, cho phép ta xác định xem có sự khác biệt đáng kể giữa các nhóm hay không.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa ANOVA",
                "text": "Định nghĩa ANOVA: phương pháp thống kê được sử dụng để kiểm định sự khác biệt giữa trung bình của nhiều nhóm.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["phương pháp thống kê", "kỹ thuật thống kê"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["kiểm định khác biệt", "trung bình", "nhiều nhóm"], "score_if_met": 4.0, "partial_score_per_keyword": 1.33}
                ]
            },
            {
                "id": "Cơ chế hoạt động ANOVA",
                "text": "Cách hoạt động của ANOVA: chia tổng phương sai thành các phần có thể quy cho các nguồn khác nhau.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["chia tổng phương sai", "nguồn khác nhau"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q37",
        "question": "Luật kết hợp (association rule) là gì? Cho ví dụ.",
        "sample_answer_text": "Luật kết hợp (association rule) là một quy tắc được rút ra từ dữ liệu, thể hiện mối quan hệ giữa các mục (items) trong một tập dữ liệu. Ví dụ: \"Nếu khách hàng mua sữa và bánh mì, thì có khả năng họ cũng sẽ mua cà phê\" là một luật kết hợp.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Luật kết hợp",
                "text": "Định nghĩa Luật kết hợp: quy tắc được rút ra từ dữ liệu, thể hiện mối quan hệ giữa các mục (items) trong một tập dữ liệu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["quy tắc", "rút ra từ dữ liệu"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "OR_KEYWORDS", "keywords": ["mối quan hệ giữa các mục", "mối liên hệ giữa sản phẩm"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Ví dụ Luật kết hợp",
                "text": "Cho ví dụ: Nếu khách hàng mua A, thì có khả năng họ cũng sẽ mua B.",
                "weight": 5.0,
                "conditions": [
                    {"type": "EXAMPLE", "keywords": ["nếu", "thì", "mua", "khả năng"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q38",
        "question": "Support, Confidence và Lift là gì? Giải thích ý nghĩa và cách tính.",
        "sample_answer_text": "Support (độ hỗ trợ) là tỷ lệ các giao dịch chứa cả hai mục A và B trong tổng số giao dịch. Công thức tính: support(A→B)=n(A∪B)/N, trong đó n(A∪B) là số giao dịch chứa A và B, và N là tổng số giao dịch. Ý nghĩa: Cho biết mức độ phổ biến của một tập mục trong dữ liệu. Confidence (độ tin cậy) là tỷ lệ các giao dịch chứa B trong các giao dịch đã chứa A. Công thức tính: confidence(A→B)=n(A∪B)/n(A), trong đó n(A) là số giao dịch chứa A. Ý nghĩa: Cho biết độ tin cậy của luật, tức là khả năng B xuất hiện khi A đã xuất hiện. Lift là tỷ lệ giữa độ tin cậy của luật và độ phổ biến của B. Công thức tính: lift(A→B)=confidence(A→B)/support(B). Ý nghĩa: Cho biết mức độ tương quan giữa A và B. Lift > 1 cho thấy A và B có tương quan thuận, Lift < 1 cho thấy tương quan nghịch và Lift = 1 cho thấy A và B độc lập.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Support",
                "text": "Support (độ hỗ trợ): tỷ lệ các giao dịch chứa cả A và B trong tổng số giao dịch. Công thức: n(A∪B)/N. Ý nghĩa: Mức độ phổ biến của một tập mục.",
                "weight": 3.33,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tỷ lệ giao dịch", "chứa cả a và b", "tổng số giao dịch"], "score_if_met": 1.33, "partial_score_per_keyword": 0.66},
                    {"type": "FORMULA", "formula_keywords": ["n(a∪b)", "n"], "score_if_met": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["mức độ phổ biến"], "score_if_met": 1.0}
                ]
            },
            {
                "id": "Confidence",
                "text": "Confidence (độ tin cậy): tỷ lệ các giao dịch chứa B trong các giao dịch đã chứa A. Công thức: n(A∪B)/n(A). Ý nghĩa: Độ tin cậy của luật, khả năng B xuất hiện khi A đã xuất hiện.",
                "weight": 3.33,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tỷ lệ giao dịch", "chứa b khi có a"], "score_if_met": 1.33, "partial_score_per_keyword": 0.66},
                    {"type": "FORMULA", "formula_keywords": ["n(a∪b)", "n(a)"], "score_if_met": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["độ tin cậy", "khả năng b xuất hiện khi a"], "score_if_met": 1.0}
                ]
            },
            {
                "id": "Lift",
                "text": "Lift: tỷ lệ giữa độ tin cậy của luật và độ phổ biến của B. Công thức: confidence(A→B)/support(B). Ý nghĩa: Mức độ tương quan giữa A và B (Lift > 1: tương quan thuận, < 1: tương quan nghịch, = 1: độc lập).",
                "weight": 3.34,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tỷ lệ", "độ tin cậy", "độ phổ biến của b"], "score_if_met": 1.34, "partial_score_per_keyword": 0.67},
                    {"type": "FORMULA", "formula_keywords": ["confidence(a→b)", "support(b)"], "score_if_met": 1.0},
                    {"type": "AND_KEYWORDS", "keywords": ["mức độ tương quan", "lift > 1", "lift < 1", "lift = 1"], "score_if_met": 1.0, "partial_score_per_keyword": 0.25}
                ]
            }
        ]
    },
    {
        "id": "Q39",
        "question": "Thuật toán Apriori là gì? Mô tả các bước của thuật toán Apriori.",
        "sample_answer_text": "Thuật toán Apriori là một thuật toán phổ biến được sử dụng để tìm các tập mục thường xuyên (frequent itemset) trong khai phá luật kết hợp. Các bước của thuật toán Apriori: Bước 1: Tìm tất cả các tập mục 1-itemset thường xuyên (L1) bằng cách đếm tần suất xuất hiện của từng mục và chọn những mục có độ hỗ trợ lớn hơn hoặc bằng min_sup. Bước 2: Sử dụng L1 để tìm tập các 2-itemset thường xuyên (L2). Bước 3: Tiếp tục quá trình này bằng cách sử dụng Lk để tạo Lk+1, cho đến khi không tìm thấy thêm tập mục thường xuyên nào. Bước 4: Tạo luật kết hợp từ các tập mục thường xuyên đã tìm được.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Apriori",
                "text": "Định nghĩa Thuật toán Apriori: tìm các tập mục thường xuyên (frequent itemset) trong khai phá luật kết hợp.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tìm tập mục thường xuyên", "khai phá luật kết hợp"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            },
            {
                "id": "Các bước Apriori",
                "text": "Các bước của thuật toán Apriori: 1. Tìm L1 (1-itemset, min_sup). 2. Sử dụng L1 để tìm L2. 3. Tiếp tục Lk -> Lk+1 cho đến khi không tìm thấy. 4. Tạo luật kết hợp từ tập mục thường xuyên.",
                "weight": 7.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["1-itemset", "min_sup"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "AND_KEYWORDS", "keywords": ["l1 để tìm l2", "2-itemset"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "AND_KEYWORDS", "keywords": ["tiếp tục lk", "không tìm thấy thêm"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "AND_KEYWORDS", "keywords": ["tạo luật kết hợp", "từ tập mục thường xuyên"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            }
        ]
    },
    {
        "id": "Q40",
        "question": "Frequent itemset (tập mục thường xuyên) là gì? Làm thế nào để tìm frequent itemset?",
        "sample_answer_text": "Frequent itemset (tập mục thường xuyên) là một tập các mục (items) có độ hỗ trợ (support) lớn hơn hoặc bằng một ngưỡng tối thiểu (min_sup) cho trước. Frequent itemset được tìm bằng cách sử dụng các thuật toán như Apriori, bằng cách đếm tần suất xuất hiện của các tập mục và chọn ra các tập mục thỏa mãn ngưỡng min_sup.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Frequent itemset",
                "text": "Định nghĩa Frequent itemset: tập các mục có độ hỗ trợ (support) lớn hơn hoặc bằng một ngưỡng tối thiểu (min_sup) cho trước.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tập các mục", "nhóm sản phẩm"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["độ hỗ trợ lớn hơn", "min_sup"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            },
            {
                "id": "Cách tìm Frequent itemset",
                "text": "Cách tìm Frequent itemset: sử dụng các thuật toán như Apriori, bằng cách đếm tần suất xuất hiện của các tập mục và chọn ra các tập mục thỏa mãn ngưỡng min_sup.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thuật toán apriori", "sử dụng thuật toán"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["đếm tần suất", "thỏa mãn ngưỡng min_sup"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q41",
        "question": "Tìm hiểu về ứng dụng của luật kết hợp trong phân tích giỏ hàng.",
        "sample_answer_text": "Luật kết hợp được ứng dụng rộng rãi trong phân tích giỏ hàng để xác định các mặt hàng thường được mua cùng nhau. Từ đó, các nhà bán lẻ có thể: Thiết kế gian hàng: Sắp xếp các mặt hàng thường được mua cùng nhau ở gần nhau để tăng doanh số. Lên kế hoạch bán giảm giá: Áp dụng các chương trình khuyến mãi cho nhóm mặt hàng mua chung. Lên kế hoạch tiếp thị/quảng cáo: Để đề xuất các sản phẩm mua kèm dựa trên lịch sử mua hàng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Mục đích ứng dụng luật kết hợp",
                "text": "Mục đích ứng dụng: xác định các mặt hàng thường được mua cùng nhau.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mua cùng nhau", "liên quan đến nhau", "đồng xuất hiện"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Ứng dụng cụ thể trong bán lẻ",
                "text": "Các ứng dụng cụ thể trong bán lẻ: Thiết kế gian hàng, Lên kế hoạch bán giảm giá, Lên kế hoạch tiếp thị/quảng cáo.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thiết kế gian hàng", "sắp xếp sản phẩm"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["bán giảm giá", "khuyến mãi"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["tiếp thị", "quảng cáo", "đề xuất sản phẩm"], "score_if_met": 2.5}
                ]
            }
        ]
    },

    {
        "id": "Q42",
        "question": "Phân biệt giữa luật kết hợp và phân loại.",
        "sample_answer_text": "Luật kết hợp tìm kiếm các mối quan hệ giữa các mục trong một tập dữ liệu, không có biến mục tiêu cụ thể. Phân loại (classification) là quá trình gán các đối tượng vào các lớp (categories) được xác định trước dựa trên các thuộc tính của đối tượng. Phân loại sử dụng các mô hình học có giám sát, trong khi luật kết hợp là học không giám sát.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Đặc điểm Luật kết hợp",
                "text": "Luật kết hợp: tìm kiếm các mối quan hệ giữa các mục, không có biến mục tiêu cụ thể, học không giám sát.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mối quan hệ giữa các mục", "liên kết giữa các sản phẩm"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["không có biến mục tiêu", "học không giám sát", "unsupervised learning"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Đặc điểm Phân loại",
                "text": "Phân loại: gán các đối tượng vào các lớp (categories) được xác định trước, sử dụng các mô hình học có giám sát.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["gán đối tượng vào lớp", "lớp xác định trước"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "OR_KEYWORDS", "keywords": ["học có giám sát", "supervised learning"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q43",
        "question": "Min support và min confidence là gì? Vai trò của chúng trong việc tìm kiếm luật kết hợp.",
        "sample_answer_text": "Min support (độ hỗ trợ tối thiểu) là ngưỡng tối thiểu để một tập mục được coi là thường xuyên. Min confidence (độ tin cậy tối thiểu) là ngưỡng tối thiểu để một luật kết hợp được coi là mạnh. Chúng giúp loại bỏ các tập mục và luật không phổ biến, hoặc không đáng tin cậy, giúp tập trung vào những luật có ý nghĩa thống kê.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Min support",
                "text": "Định nghĩa Min support: ngưỡng tối thiểu để một tập mục được coi là thường xuyên.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["ngưỡng tối thiểu", "tập mục thường xuyên"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75}
                ]
            },
            {
                "id": "Định nghĩa Min confidence",
                "text": "Định nghĩa Min confidence: ngưỡng tối thiểu để một luật kết hợp được coi là mạnh.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["ngưỡng tối thiểu", "luật kết hợp mạnh"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75}
                ]
            },
            {
                "id": "Vai trò chung Min support/confidence",
                "text": "Vai trò chung: giúp loại bỏ các tập mục và luật không phổ biến, hoặc không đáng tin cậy, giúp tập trung vào những luật có ý nghĩa thống kê.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["loại bỏ luật không phổ biến", "không đáng tin cậy", "ý nghĩa thống kê"], "score_if_met": 3.0}
                ]
            }
        ]
    },
    {
        "id": "Q44",
        "question": "Cho ví dụ về việc áp dụng luật kết hợp trong lĩnh vực kinh doanh.",
        "sample_answer_text": "Trong kinh doanh, luật kết hợp có thể được áp dụng để: Phân tích hành vi mua sắm trực tuyến: Đề xuất sản phẩm liên quan cho khách hàng. Phân tích dữ liệu giỏ dịch: Tìm ra các nhóm sản phẩm thường được mua cùng nhau để có các chiến lược marketing phù hợp. Tối ưu hóa vị trí sản phẩm trong siêu thị: Sắp xếp các sản phẩm liên quan gần nhau.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Ứng dụng E-commerce",
                "text": "Ứng dụng trong Phân tích hành vi mua sắm trực tuyến: Đề xuất sản phẩm liên quan cho khách hàng.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["đề xuất sản phẩm", "mua sắm trực tuyến"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75}
                ]
            },
            {
                "id": "Ứng dụng phân tích giỏ hàng",
                "text": "Ứng dụng trong Phân tích dữ liệu giỏ dịch: Tìm ra các nhóm sản phẩm thường được mua cùng nhau để có các chiến lược marketing phù hợp.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["nhóm sản phẩm mua chung", "chiến lược marketing"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75}
                ]
            },
            {
                "id": "Ứng dụng tối ưu vị trí sản phẩm",
                "text": "Ứng dụng trong Tối ưu hóa vị trí sản phẩm trong siêu thị: Sắp xếp các sản phẩm liên quan gần nhau.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["sắp xếp sản phẩm", "siêu thị"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q45",
        "question": "Thế nào là luật kết hợp mạnh?",
        "sample_answer_text": "Luật kết hợp mạnh là luật kết hợp thỏa mãn cả hai điều kiện: độ hỗ trợ (support) lớn hơn hoặc bằng min_sup và độ tin cậy (confidence) lớn hơn hoặc bằng min_confidence.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điều kiện Support",
                "text": "Điều kiện về Support: độ hỗ trợ (support) lớn hơn hoặc bằng min_sup.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["support lớn hơn", "min_sup"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5}
                ]
            },
            {
                "id": "Điều kiện Confidence",
                "text": "Điều kiện về Confidence: độ tin cậy (confidence) lớn hơn hoặc bằng min_confidence.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["confidence lớn hơn", "min_confidence"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q46",
        "question": "Làm thế nào để đánh giá chất lượng của một luật kết hợp?",
        "sample_answer_text": "Chất lượng của một luật kết hợp có thể được đánh giá bằng cách sử dụng các độ đo: Support: Cho biết mức độ phổ biến của tập mục. Confidence: Cho biết độ tin cậy của luật. Lift: Cho biết mức độ tương quan giữa các mục. Ngoài ra, có thể sử dụng thêm một số độ đo khác như conviction, leverage, etc.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các độ đo chính",
                "text": "Nêu các độ đo chính: Support (mức độ phổ biến), Confidence (độ tin cậy), Lift (mức độ tương quan).",
                "weight": 7.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["support", "phổ biến"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "AND_KEYWORDS", "keywords": ["confidence", "tin cậy"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "AND_KEYWORDS", "keywords": ["lift", "tương quan"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Các độ đo bổ sung",
                "text": "Nêu các độ đo bổ sung: conviction, leverage.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["conviction", "leverage", "độ đo khác"], "score_if_met": 3.0}
                ]
            }
        ]
    },
    {
        "id": "Q47",
        "question": "Phân cụm (clustering) là gì? Mục tiêu của phân cụm.",
        "sample_answer_text": "Phân cụm (clustering) là một kỹ thuật phân tích dữ liệu không giám sát nhằm mục đích chia một tập dữ liệu thành các nhóm (cụm) sao cho các đối tượng trong cùng một cụm tương đồng với nhau hơn so với các đối tượng của các cụm khác. Mục tiêu của phân cụm là: Tìm ra các nhóm dữ liệu có ý nghĩa trong tập dữ liệu. Phân loại dữ liệu một cách tự động. Rút trích thông tin từ dữ liệu phức tạp. Tiền xử lý dữ liệu cho các thuật toán khác.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Phân cụm",
                "text": "Định nghĩa Phân cụm: kỹ thuật phân tích dữ liệu không giám sát nhằm chia một tập dữ liệu thành các nhóm (cụm) sao cho các đối tượng trong cùng một cụm tương đồng với nhau hơn so với các đối tượng của các cụm khác.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không giám sát", "unsupervised"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["chia dữ liệu", "cụm"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "AND_KEYWORDS", "keywords": ["tương đồng trong cụm", "khác biệt giữa cụm"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Mục tiêu Phân cụm",
                "text": "Mục tiêu của Phân cụm: Tìm ra các nhóm dữ liệu có ý nghĩa, Phân loại dữ liệu tự động, Rút trích thông tin, Tiền xử lý dữ liệu.",
                "weight": 4.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["tìm nhóm dữ liệu có ý nghĩa", "phân loại dữ liệu tự động", "rút trích thông tin", "tiền xử lý dữ liệu"], "min_count": 2, "score_per_keyword": 2.0, "max_score_for_condition": 4.0, "partial_score_if_less": [{"count": 1, "score": 2.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q48",
        "question": "K-means clustering là gì? Mô tả thuật toán K-means.",
        "sample_answer_text": "K-means clustering là một thuật toán phân cụm theo phân hoạch, nhằm chia dữ liệu thành K cụm, trong đó mỗi cụm được đại diện bởi trọng tâm (centroid) của nó. Các bước của thuật toán K-means: Bước 1: Chọn ngẫu nhiên K điểm dữ liệu làm trọng tâm ban đầu cho K cụm. Bước 2: Gán mỗi điểm dữ liệu vào cụm có trọng tâm gần nhất (thường dùng khoảng cách Euclidean). Bước 3: Tính toán lại trọng tâm mới cho mỗi cụm dựa trên các điểm dữ liệu đã được gán vào. Bước 4: Lặp lại bước 2 và 3 cho đến khi không còn sự thay đổi trong việc gán điểm dữ liệu vào các cụm.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa K-means",
                "text": "Định nghĩa K-means: thuật toán phân cụm theo phân hoạch, chia dữ liệu thành K cụm, mỗi cụm được đại diện bởi trọng tâm (centroid) của nó.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["phân cụm theo phân hoạch", "chia k cụm"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["trọng tâm", "centroid"], "score_if_met": 1.5}
                ]
            },
            {
                "id": "Các bước K-means",
                "text": "Các bước của thuật toán K-means: 1. Chọn ngẫu nhiên K trọng tâm ban đầu. 2. Gán mỗi điểm dữ liệu vào cụm có trọng tâm gần nhất. 3. Tính toán lại trọng tâm mới. 4. Lặp lại đến khi không còn thay đổi.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chọn ngẫu nhiên k điểm", "trọng tâm ban đầu"], "score_if_met": 1.75},
                    {"type": "AND_KEYWORDS", "keywords": ["gán điểm", "trọng tâm gần nhất"], "score_if_met": 1.75, "partial_score_per_keyword": 0.875},
                    {"type": "OR_KEYWORDS", "keywords": ["tính lại trọng tâm mới"], "score_if_met": 1.75},
                    {"type": "AND_KEYWORDS", "keywords": ["lặp lại", "không thay đổi"], "score_if_met": 1.75, "partial_score_per_keyword": 0.875}
                ]
            }
        ]
    },
    {
        "id": "Q49",
        "question": "Cách chọn số cụm K trong K-means?",
        "sample_answer_text": "Việc chọn số cụm K trong K-means là một thách thức, vì không có quy tắc chung nào có thể áp dụng cho mọi trường hợp. Một số phương pháp thường được sử dụng: Phương pháp Elbow: Vẽ biểu đồ sự thay đổi của tổng bình phương khoảng cách trong cụm (WCSS) theo số lượng cụm, K. Chọn K tại \"điểm khuỷu tay\" trên biểu đồ. Phương pháp Silhouette: Tính toán chỉ số Silhouette cho các số lượng cụm khác nhau và chọn K sao cho chỉ số này đạt giá trị lớn nhất. Sử dụng kiến thức chuyên gia hoặc mục tiêu cụ thể của bài toán để quyết định số cụm phù hợp.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Phương pháp Elbow",
                "text": "Phương pháp Elbow: Vẽ biểu đồ WCSS theo số lượng cụm K và chọn K tại \"điểm khuỷu tay\".",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["elbow", "wcss", "điểm khuỷu tay"], "score_if_met": 4.0, "partial_score_per_keyword": 1.33}
                ]
            },
            {
                "id": "Phương pháp Silhouette",
                "text": "Phương pháp Silhouette: Tính toán chỉ số Silhouette và chọn K có chỉ số lớn nhất.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["silhouette", "chỉ số silhouette", "lớn nhất"], "score_if_met": 4.0, "partial_score_per_keyword": 1.33}
                ]
            },
            {
                "id": "Kiến thức chuyên gia/Mục tiêu bài toán",
                "text": "Sử dụng kiến thức chuyên gia hoặc mục tiêu cụ thể của bài toán.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["kiến thức chuyên gia", "mục tiêu bài toán"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q50",
        "question": "Tại sao cần chuẩn hóa dữ liệu trước khi phân cụm?",
        "sample_answer_text": "Chuẩn hóa dữ liệu (normalization) là cần thiết trước khi phân cụm vì các lý do sau: Khắc phục sự khác biệt về thang đo: Các thuộc tính khác nhau có thể có thang đo khác nhau, ví dụ tuổi (0-100) và thu nhập (0-100000). Chuẩn hóa giúp đưa các thuộc tính về cùng một thang đo. Tránh thuộc tính có giá trị lớn chi phối kết quả: Nếu không chuẩn hóa, các thuộc tính có giá trị lớn sẽ có ảnh hưởng lớn hơn đến quá trình tính khoảng cách, làm sai lệch kết quả phân cụm. Nâng cao hiệu quả của thuật toán: Các thuật tính phân cụm thường hoạt động tốt hơn với dữ liệu đã được chuẩn hóa. Đảm bảo các thuộc tính có vai trò ngang nhau trong quá trình phân cụm, tránh các thuộc tính có giá trị lớn làm sai lệch kết quả.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Khắc phục khác biệt thang đo",
                "text": "Khắc phục sự khác biệt về thang đo: đưa các thuộc tính về cùng một thang đo.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thang đo khác nhau", "cùng thang đo"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Tránh thuộc tính lớn chi phối",
                "text": "Tránh thuộc tính có giá trị lớn chi phối kết quả: làm sai lệch kết quả phân cụm, ảnh hưởng đến khoảng cách.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giá trị lớn chi phối", "sai lệch kết quả", "ảnh hưởng đến khoảng cách"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Nâng cao hiệu quả thuật toán",
                "text": "Nâng cao hiệu quả của thuật toán và Đảm bảo các thuộc tính có vai trò ngang nhau.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["hiệu quả thuật toán", "hoạt động tốt hơn"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["vai trò ngang nhau", "ảnh hưởng đều"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q51",
        "question": "Chuỗi thời gian (time series) là gì? Cho ví dụ.",
        "sample_answer_text": "Chuỗi thời gian (time series) là một tập hợp các quan sát được thu thập theo thời gian. Ví dụ: Doanh số bán hàng hàng tháng của một công ty. Giá cổ phiếu hàng ngày của một công ty. Nhiệt độ trung bình năm của một thành phố. Số lượng khách hàng truy cập vào một website mỗi giờ.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Chuỗi thời gian",
                "text": "Định nghĩa Chuỗi thời gian: tập hợp các quan sát được thu thập theo thời gian.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tập hợp quan sát", "dãy số liệu"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["theo thời gian", "qua các giai đoạn thời gian"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Ví dụ Chuỗi thời gian",
                "text": "Cho ví dụ: Doanh số bán hàng, Giá cổ phiếu, Nhiệt độ, Lưu lượng truy cập.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["doanh số bán hàng", "giá cổ phiếu", "nhiệt độ", "lưu lượng truy cập"], "min_count": 2, "score_per_keyword": 2.5, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 1, "score": 2.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q52",
        "question": "Dự báo (forecasting) là gì? Mục tiêu của dự báo.",
        "sample_answer_text": "Dự báo (forecasting) là quá trình sử dụng dữ liệu trong quá khứ và hiện tại để dự đoán các giá trị trong tương lai. Mục tiêu của dự báo là: Hỗ trợ ra quyết định trong các lĩnh vực khác nhau. Lập kế hoạch sản xuất, kinh doanh, tài chính. Quản lý rủi ro và tối ưu hóa nguồn lực.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Dự báo",
                "text": "Định nghĩa Dự báo: quá trình sử dụng dữ liệu trong quá khứ và hiện tại để dự đoán các giá trị trong tương lai.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["dữ liệu quá khứ", "dữ liệu hiện tại"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25},
                    {"type": "OR_KEYWORDS", "keywords": ["dự đoán tương lai", "ước tính giá trị sắp tới"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Mục tiêu Dự báo",
                "text": "Mục tiêu của Dự báo: Hỗ trợ ra quyết định, Lập kế hoạch, Quản lý rủi ro và tối ưu hóa nguồn lực.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["hỗ trợ ra quyết định", "lập kế hoạch", "quản lý rủi ro", "tối ưu hóa nguồn lực"], "min_count": 2, "score_per_keyword": 2.5, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 1, "score": 2.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q53",
        "question": "Phương pháp bình quân di động (moving average) là gì? Cách tính bình quân di động.",
        "sample_answer_text": "Phương pháp bình quân di động (moving average) là một phương pháp làm mịn chuỗi thời gian bằng cách tính trung bình của một số lượng quan sát gần nhất. Cách tính bình quân di động: Chọn một cửa sổ (window) có độ dài n. Tại mỗi thời điểm t, tính trung bình của n giá trị quan sát trước đó (t−1,t−2,...,t−n). Công thức: Mat​=(Yt−1​+Yt−2​+...+Yt−n​)/n. Phương pháp này giúp loại bỏ các biến động ngắn hạn và làm nổi bật xu hướng dài hạn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Bình quân di động",
                "text": "Định nghĩa Bình quân di động: phương pháp làm mịn chuỗi thời gian bằng cách tính trung bình của một số lượng quan sát gần nhất.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["làm mịn chuỗi thời gian", "giảm nhiễu chuỗi thời gian"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["trung bình", "quan sát gần nhất"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Cách tính Bình quân di động",
                "text": "Cách tính Bình quân di động: chọn cửa sổ n, tính trung bình của n giá trị trước đó. Công thức: Mat=(Yt-1+...+Yt-n)/n.",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["chọn cửa sổ", "trung bình của n giá trị trước"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5},
                    {"type": "FORMULA", "formula_keywords": ["yt", "n", "/"], "score_if_met": 3.0}
                ]
            }
        ]
    },
    {
        "id": "Q54",
        "question": "Phân cụm phân cấp (hierarchical clustering) là gì?",
        "sample_answer_text": "Phân cụm phân cấp (hierarchical clustering) là một phương pháp phân cụm mà tạo ra một cấu trúc phân cấp của các cụm dữ liệu. Phương pháp này không yêu cầu xác định trước số cụm, mà thay vào đó xây dựng một cây phân cấp (dendrogram) để biểu diễn các mối quan hệ giữa các cụm ở các mức khác nhau.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Phân cụm phân cấp",
                "text": "Định nghĩa Phân cụm phân cấp: phương pháp phân cụm tạo ra một cấu trúc phân cấp của các cụm dữ liệu, không yêu cầu xác định trước số cụm.",
                "weight": 7.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["phương pháp phân cụm", "cấu trúc phân cấp"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["không cần số cụm trước", "không xác định k"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Đầu ra Phân cụm phân cấp",
                "text": "Cách hoạt động/Đầu ra: xây dựng một cây phân cấp (dendrogram) để biểu diễn các mối quan hệ giữa các cụm.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["cây phân cấp", "dendrogram", "biểu diễn mối quan hệ"], "score_if_met": 3.0, "partial_score_per_keyword": 1.0}
                ]
            }
        ]
    },
    {
        "id": "Q55",
        "question": "Phân biệt giữa phân cụm phân cấp agglomerative và divisive.",
        "sample_answer_text": "Phân cụm phân cấp agglomerative (từ dưới lên): Bắt đầu bằng việc coi mỗi điểm dữ liệu là một cụm riêng biệt, sau đó lặp đi lặp lại việc hợp nhất các cụm gần nhau nhất cho đến khi chỉ còn một cụm lớn bao gồm tất cả các điểm. Phân cụm phân cấp divisive (từ trên xuống): Bắt đầu bằng việc coi tất cả các điểm dữ liệu thuộc cùng một cụm, sau đó lặp đi lặp lại việc chia tách cụm này thành các cụm nhỏ hơn cho đến khi mỗi điểm dữ liệu là một cụm riêng biệt.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Agglomerative",
                "text": "Agglomerative (từ dưới lên): Bắt đầu với mỗi điểm là một cụm, sau đó hợp nhất các cụm gần nhau nhất.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["từ dưới lên", "bottom-up"], "score_if_met": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["mỗi điểm là một cụm"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["hợp nhất cụm", "ghép cụm"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Divisive",
                "text": "Divisive (từ trên xuống): Bắt đầu với tất cả điểm là một cụm, sau đó chia tách cụm này thành các cụm nhỏ hơn.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["từ trên xuống", "top-down"], "score_if_met": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["tất cả điểm là một cụm"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["chia tách cụm", "phân chia cụm"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q56",
        "question": "Dendrogram là gì? Cách đọc dendrogram.",
        "sample_answer_text": "Dendrogram là một biểu đồ dạng cây được sử dụng để trực quan hóa kết quả của phân cụm phân cấp. Cách đọc dendrogram: Trục hoành biểu diễn các điểm dữ liệu hoặc các cụm đã được hợp nhất. Trục tung biểu diễn khoảng cách hoặc độ tương đồng giữa các cụm. Các nhánh cây thể hiện quá trình hợp nhất các cụm; nhánh càng cao thì khoảng cách/độ không tương đồng giữa các cụm càng lớn. Việc cắt ngang cây tại một độ cao nhất định sẽ tạo thành các cụm.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Dendrogram",
                "text": "Định nghĩa Dendrogram: biểu đồ dạng cây để trực quan hóa kết quả phân cụm phân cấp.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["biểu đồ cây", "trực quan hóa", "phân cụm phân cấp"], "score_if_met": 3.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Cách đọc Dendrogram",
                "text": "Cách đọc Dendrogram: Trục hoành (điểm dữ liệu/cụm), Trục tung (khoảng cách/độ tương đồng), Các nhánh cây (quá trình hợp nhất, độ cao nhánh), Cắt ngang cây (tạo cụm).",
                "weight": 7.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["trục hoành", "điểm dữ liệu"], "score_if_met": 1.75, "partial_score_per_keyword": 0.875},
                    {"type": "AND_KEYWORDS", "keywords": ["trục tung", "khoảng cách", "độ tương đồng"], "score_if_met": 1.75, "partial_score_per_keyword": 0.58},
                    {"type": "AND_KEYWORDS", "keywords": ["nhánh cây", "hợp nhất", "khoảng cách lớn"], "score_if_met": 1.75, "partial_score_per_keyword": 0.58},
                    {"type": "AND_KEYWORDS", "keywords": ["cắt ngang cây", "tạo cụm"], "score_if_met": 1.75, "partial_score_per_keyword": 0.875}
                ]
            }
        ]
    },
    {
        "id": "Q57",
        "question": "Ưu điểm và nhược điểm của phân cụm phân cấp.",
        "sample_answer_text": "Ưu điểm của phân cụm phân cấp: Không yêu cầu xác định trước số cụm. Cung cấp cấu trúc phân cấp các cụm, cho phép phân tích ở nhiều mức độ. Dễ dàng trực quan hóa bằng dendrogram. Nhược điểm của phân cụm phân cấp: Độ phức tạp tính toán cao hơn so với K-means, đặc biệt với dữ liệu lớn. Kết quả phân cụm có thể bị ảnh hưởng bởi lựa chọn phương pháp tính khoảng cách và liên kết cụm.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Ưu điểm phân cụm phân cấp",
                "text": "Ưu điểm: Không yêu cầu xác định trước số cụm, Cung cấp cấu trúc phân cấp các cụm, Dễ dàng trực quan hóa bằng dendrogram.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không cần số cụm trước", "không xác định k"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["cấu trúc phân cấp", "nhiều mức độ"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["trực quan hóa", "dendrogram"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Nhược điểm phân cụm phân cấp",
                "text": "Nhược điểm: Độ phức tạp tính toán cao hơn, Kết quả có thể bị ảnh hưởng bởi lựa chọn phương pháp tính khoảng cách và liên kết cụm.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["độ phức tạp cao", "dữ liệu lớn"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["ảnh hưởng bởi khoảng cách", "liên kết cụm"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q58",
        "question": "Thế nào là khoảng cách Euclidean?",
        "sample_answer_text": "Khoảng cách Euclidean là một cách đo khoảng cách giữa hai điểm trong không gian đa chiều. Khoảng cách này được tính bằng căn bậc hai của tổng bình phương các hiệu số giữa các tọa độ của hai điểm. Công thức tính khoảng cách Euclidean giữa hai điểm p(p1​,p2​,...,pn​) và q(q1​,q2​,...,qn​) trong không gian n chiều là: √((q₁-p₁)² + (q₂-p₂)² + ... + (qₙ-pₙ)²).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa khoảng cách Euclidean",
                "text": "Định nghĩa Khoảng cách Euclidean: cách đo khoảng cách giữa hai điểm trong không gian đa chiều.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["đo khoảng cách", "hai điểm", "không gian đa chiều"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            },
            {
                "id": "Cách tính khoảng cách Euclidean",
                "text": "Cách tính: căn bậc hai của tổng bình phương các hiệu số giữa các tọa độ. Công thức: √((q₁-p₁)² + ... + (qₙ-pₙ)²).",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["căn bậc hai", "tổng bình phương", "hiệu số tọa độ"], "score_if_met": 2.5, "partial_score_per_keyword": 0.83},
                    {"type": "FORMULA", "formula_keywords": ["q", "p", "bình phương", "tổng", "căn"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q59",
        "question": "Phương pháp làm mịn mũ (exponential smoothing) là gì? Cách tính làm mịn mũ.",
        "sample_answer_text": "Phương pháp làm mịn mũ (exponential smoothing) là một phương pháp dự báo chuỗi thời gian mà gán trọng số giảm dần theo cấp số nhân cho các quan sát cũ hơn, trong đó các quan sát gần nhất có trọng số lớn nhất. Cách tính làm mịn mũ: Chọn một hệ số làm mịn α (0<α<1). Tính giá trị dự báo tại thời điểm t bằng công thức: St​=αYt​+(1−α)St−1​, với St​ là giá trị làm mịn tại thời điểm t. Phương pháp này linh hoạt hơn so với bình quân di động vì có thể điều chỉnh trọng số cho các quan sát gần nhất và cũ hơn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa làm mịn mũ",
                "text": "Định nghĩa Làm mịn mũ: phương pháp dự báo chuỗi thời gian mà gán trọng số giảm dần theo cấp số nhân cho các quan sát cũ hơn (quan sát gần nhất có trọng số lớn nhất).",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dự báo chuỗi thời gian", "mô hình chuỗi thời gian"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["trọng số giảm dần", "cấp số nhân", "quan sát gần nhất trọng số lớn"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Cách tính làm mịn mũ",
                "text": "Cách tính Làm mịn mũ: Chọn hệ số làm mịn α (0<α<1). Công thức: St​=αYt​+(1−α)St−1​.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["hệ số làm mịn alpha", "0<α<1"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "FORMULA", "formula_keywords": ["st", "αyt", "(1−α)st−1"], "score_if_met": 3.5}
                ]
            }
        ]
    },
    {
        "id": "Q60",
        "question": "Mô hình hồi quy tuyến tính (linear regression) trong dự báo chuỗi thời gian.",
        "sample_answer_text": "Mô hình hồi quy tuyến tính có thể được sử dụng để dự báo chuỗi thời gian khi có một mối quan hệ tuyến tính giữa chuỗi thời gian và hoặc nhiều biến độc lập khác, chẳng hạn như thời gian hoặc các yếu tố khác ảnh hưởng đến chuỗi. Trong mô hình này, chuỗi thời gian được xem như một biến phụ thuộc, và các biến thời gian hay các yếu tố ảnh hưởng sẽ là biến độc lập.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điều kiện sử dụng Linear Regression",
                "text": "Điều kiện sử dụng: dự báo chuỗi thời gian khi có mối quan hệ tuyến tính giữa chuỗi thời gian và biến độc lập khác (thời gian hoặc yếu tố ảnh hưởng).",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dự báo chuỗi thời gian", "time series forecasting"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["mối quan hệ tuyến tính", "tuyến tính"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["biến độc lập", "thời gian", "yếu tố ảnh hưởng"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Vai trò biến Linear Regression",
                "text": "Vai trò biến: chuỗi thời gian là biến phụ thuộc, biến thời gian hay yếu tố ảnh hưởng là biến độc lập.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chuỗi thời gian là biến phụ thuộc", "y là chuỗi thời gian"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["biến thời gian", "yếu tố ảnh hưởng", "x là biến độc lập"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q61",
        "question": "Mô hình ARIMA là gì? Giải thích các tham số p, d, q trong ARIMA.",
        "sample_answer_text": "Mô hình ARIMA (Autoregressive Integrated Moving Average) là một mô hình dự báo chuỗi thời gian kết hợp các thành phần tự hồi quy (AR), tích hợp (I), và trung bình trượt (MA). Các tham số trong ARIMA: p (Autoregressive - AR): Số lượng các độ trễ của chuỗi thời gian được sử dụng làm biến đầu vào trong mô hình. d (Integrated - I): Số lần sai phân (differencing) cần thiết để làm cho chuỗi thời gian trở nên dừng. q (Moving Average - MA): Số lượng các sai số dự báo trễ được sử dụng làm biến đầu vào trong mô hình.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa ARIMA và thành phần",
                "text": "Định nghĩa Mô hình ARIMA: mô hình dự báo chuỗi thời gian kết hợp các thành phần tự hồi quy (AR), tích hợp (I), và trung bình trượt (MA).",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mô hình dự báo chuỗi thời gian", "kết hợp các thành phần"], "score_if_met": 1.0},
                    {"type": "COUNT_KEYWORDS", "keywords": ["tự hồi quy", "ar", "tích hợp", "i", "trung bình trượt", "ma"], "min_count": 3, "score_per_keyword": 0.67, "max_score_for_condition": 2.0, "partial_score_if_less": [{"count": 2, "score": 1.0}, {"count": 1, "score": 0.5}]}
                ]
            },
            {
                "id": "Giải thích tham số p",
                "text": "Giải thích tham số p: bậc của thành phần AR, số độ trễ của chuỗi thời gian được sử dụng làm biến đầu vào.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["p", "ar", "độ trễ", "biến đầu vào"], "score_if_met": 2.0, "partial_score_per_keyword": 0.5}
                ]
            },
            {
                "id": "Giải thích tham số d",
                "text": "Giải thích tham số d: số lần sai phân (differencing) cần thiết để làm cho chuỗi thời gian trở nên dừng.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["d", "sai phân", "dừng"], "score_if_met": 2.0, "partial_score_per_keyword": 0.67}
                ]
            },
            {
                "id": "Giải thích tham số q",
                "text": "Giải thích tham số q: số lượng các sai số dự báo trễ được sử dụng làm biến đầu vào.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["q", "ma", "sai số dự báo trễ"], "score_if_met": 2.0, "partial_score_per_keyword": 0.67}
                ]
            },
            {
                "id": "Cách xác định tham số ARIMA",
                "text": "Cách xác định p, d, q: ACF và PACF (tìm cut-off), Grid search (AIC/BIC thấp nhất).",
                "weight": 1.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["acf", "pacf", "cut-off"], "score_if_met": 0.5},
                    {"type": "OR_KEYWORDS", "keywords": ["grid search", "aic", "bic"], "score_if_met": 0.5}
                ]
            }
        ]
    },
    {
        "id": "Q62",
        "question": "Thế nào là chuỗi thời gian dừng (stationary time series)? Tại sao cần kiểm tra tính dừng của chuỗi thời gian trước khi áp dụng ARIMA?",
        "sample_answer_text": "Chuỗi thời gian dừng có các đặc tính thống kê (ví dụ: trung bình, phương sai) không thay đổi theo thời gian. Cần kiểm tra tính dừng trước khi áp dụng ARIMA vì: ARIMA giả định rằng chuỗi thời gian là dừng. Nếu chuỗi không dừng, kết quả dự báo sẽ không chính xác. Cần sai phân để chuyển chuỗi không dừng thành chuỗi dừng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa chuỗi thời gian dừng",
                "text": "Định nghĩa Chuỗi thời gian dừng: các đặc tính thống kê (trung bình, phương sai) không thay đổi theo thời gian.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["đặc tính thống kê", "trung bình", "phương sai", "không thay đổi theo thời gian"], "score_if_met": 4.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Lý do kiểm tra tính dừng",
                "text": "Lý do cần kiểm tra tính dừng trước ARIMA: ARIMA giả định chuỗi thời gian là dừng, nếu không kết quả không chính xác, cần sai phân để chuyển chuỗi không dừng thành chuỗi dừng.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["arima giả định dừng", "arima yêu cầu stationary"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["kết quả không chính xác", "sai lệch"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["sai phân", "chuyển sang dừng"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            }
        ]
    },
    {
        "id": "Q63",
        "question": "ACF (Autocorrelation Function) và PACF (Partial Autocorrelation Function) là gì? Cách sử dụng ACF và PACF để xác định các tham số p, q trong ARIMA.",
        "sample_answer_text": "ACF (Autocorrelation Function): Đo mức độ tương quan giữa một chuỗi thời gian và chính nó ở các độ trễ khác nhau. PACF (Partial Autocorrelation Function): Đo mức độ tương quan giữa một chuỗi thời gian và chính nó ở các độ trễ khác nhau, sau khi đã loại bỏ ảnh hưởng của các độ trễ trung gian. Sử dụng ACF và PACF: PACF giúp xác định tham số p bằng cách tìm độ trễ mà tại đó giá trị PACF bị \"cắt\" (cut-off). ACF giúp xác định tham số q bằng cách tìm độ trễ mà tại đó giá trị ACF bị \"cắt\" (cut-off).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa ACF",
                "text": "Định nghĩa ACF: Đo mức độ tương quan giữa một chuỗi thời gian và chính nó ở các độ trễ khác nhau.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tương quan", "chuỗi thời gian", "độ trễ khác nhau"], "score_if_met": 3.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Định nghĩa PACF",
                "text": "Định nghĩa PACF: Đo mức độ tương quan giữa một chuỗi thời gian và chính nó ở các độ trễ khác nhau, sau khi đã loại bỏ ảnh hưởng của các độ trễ trung gian.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tương quan", "độ trễ khác nhau", "loại bỏ ảnh hưởng trung gian"], "score_if_met": 3.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Cách sử dụng ACF/PACF",
                "text": "Cách sử dụng ACF và PACF để xác định p, q: PACF giúp xác định p (khi PACF \"cắt\"), ACF giúp xác định q (khi ACF \"cắt\").",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["pacf", "xác định p", "cut-off"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66},
                    {"type": "AND_KEYWORDS", "keywords": ["acf", "xác định q", "cut-off"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66}
                ]
            }
        ]
    },
    {
        "id": "Q64",
        "question": "Cách đánh giá độ chính xác của mô hình dự báo. Kể tên một số độ đo đánh giá độ chính xác.",
        "sample_answer_text": "Đánh giá độ chính xác của mô hình dự báo bằng cách so sánh các giá trị dự báo với giá trị thực tế. Một số độ đo đánh giá độ chính xác: MAD (Mean Absolute Deviation): Trung bình của các sai số tuyệt đối. SSE (Sum of Squared Errors): Tổng của các bình phương sai số. MSE (Mean Squared Error): Trung bình của các bình phương sai số. RMSE (Root Mean Squared Error): Căn bậc hai của MSE. AIC (Akaike Information Criterion): Đo độ phù hợp của mô hình, mô hình có AIC nhỏ hơn được ưu tiên hơn. BIC (Bayesian Information Criterion): Tương tự như AIC, nhưng có xu hướng phạt các mô hình phức tạp hơn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Cách đánh giá chung",
                "text": "Cách đánh giá chung: so sánh các giá trị dự báo với giá trị thực tế.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["so sánh dự báo", "giá trị thực tế"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            },
            {
                "id": "Các độ đo đánh giá",
                "text": "Kể tên các độ đo đánh giá: MAD, SSE, MSE, RMSE, AIC, BIC.",
                "weight": 7.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["mad", "sse", "mse", "rmse", "aic", "bic"], "min_count": 3, "score_per_keyword": 2.33, "max_score_for_condition": 7.0, "partial_score_if_less": [{"count": 2, "score": 4.0}, {"count": 1, "score": 2.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q65",
        "question": "Cho ví dụ về ứng dụng của phân tích chuỗi thời gian và dự báo trong kinh doanh.",
        "sample_answer_text": "Ví dụ về ứng dụng trong kinh doanh: Dự báo doanh số bán hàng để lập kế hoạch sản xuất và tồn kho. Dự báo nhu cầu của khách hàng để điều chỉnh chiến lược marketing. Dự báo giá cổ phiếu để đưa ra quyết định đầu tư. Dự báo lưu lượng truy cập website để tối ưu hóa băng thông và hiệu suất website. Dự báo các xu hướng để phát triển sản phẩm và dịch vụ mới.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Ứng dụng kinh doanh",
                "text": "Đưa ra ví dụ ứng dụng: dự báo doanh số, nhu cầu khách hàng, giá cổ phiếu, lưu lượng truy cập website, xu hướng.",
                "weight": 10.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["dự báo doanh số", "dự báo nhu cầu khách hàng", "dự báo giá cổ phiếu", "dự báo lưu lượng truy cập website", "dự báo xu hướng"], "min_count": 3, "score_per_keyword": 3.33, "max_score_for_condition": 10.0, "partial_score_if_less": [{"count": 2, "score": 6.0}, {"count": 1, "score": 3.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q66",
        "question": "Phân biệt giữa chuỗi thời gian và dữ liệu chéo (cross-sectional data).",
        "sample_answer_text": "Chuỗi thời gian (time series): Dữ liệu được thu thập theo thời gian cho cùng một đối tượng hoặc biến số. Ví dụ: Theo dõi doanh thu hàng tháng của một cửa hàng trong vòng 5 năm. Dữ liệu chéo (cross-sectional data): Dữ liệu được thu thập tại một thời điểm duy nhất cho nhiều đối tượng hoặc biến số khác nhau. Ví dụ: Thu thập thông tin về doanh thu của tất cả các cửa hàng trong một chuỗi tại một thời điểm duy nhất.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa chuỗi thời gian",
                "text": "Chuỗi thời gian: Dữ liệu được thu thập theo thời gian cho cùng một đối tượng hoặc biến số.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thu thập theo thời gian", "qua các giai đoạn"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["cùng một đối tượng", "doanh thu hàng tháng của một cửa hàng"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Định nghĩa dữ liệu chéo",
                "text": "Dữ liệu chéo: Dữ liệu được thu thập tại một thời điểm duy nhất cho nhiều đối tượng hoặc biến số khác nhau.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["một thời điểm duy nhất", "tại một thời điểm"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["nhiều đối tượng", "doanh thu của tất cả các cửa hàng"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q67",
        "question": "Các thành phần của chuỗi thời gian.",
        "sample_answer_text": "Các thành phần của chuỗi thời gian bao gồm: Xu hướng (Trend): Sự tăng hoặc giảm dài hạn của chuỗi. Tính mùa vụ (Seasonality): Các biến động lặp lại trong một khoảng thời gian cố định (ví dụ: hàng năm, hàng tháng). Tính chu kỳ (Cyclical): Các biến động dài hạn không lặp lại có thể ảnh hưởng đến chuỗi. Tính ngẫu nhiên (Irregular/Random): Các biến động không thể giải thích được và không có quy luật.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Xu hướng (Trend)",
                "text": "Xu hướng (Trend): Sự tăng hoặc giảm dài hạn của chuỗi.",
                "weight": 2.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["xu hướng", "tăng dài hạn", "giảm dài hạn"], "score_if_met": 2.5, "partial_score_per_keyword": 0.83}
                ]
            },
            {
                "id": "Tính mùa vụ (Seasonality)",
                "text": "Tính mùa vụ (Seasonality): Các biến động lặp lại trong một khoảng thời gian cố định.",
                "weight": 2.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["mùa vụ", "lặp lại"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25}
                ]
            },
            {
                "id": "Tính chu kỳ (Cyclical)",
                "text": "Tính chu kỳ (Cyclical): Các biến động dài hạn không lặp lại có thể ảnh hưởng đến chuỗi.",
                "weight": 2.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["chu kỳ", "dài hạn", "không lặp lại"], "score_if_met": 2.5, "partial_score_per_keyword": 0.83}
                ]
            },
            {
                "id": "Tính ngẫu nhiên (Irregular/Random)",
                "text": "Tính ngẫu nhiên (Irregular/Random): Các biến động không thể giải thích được và không có quy luật.",
                "weight": 2.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["ngẫu nhiên", "không giải thích được"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25}
                ]
            }
        ]
    },
    {
        "id": "Q68",
        "question": "Xử lý mất cân bằng dữ liệu trong phân loại.",
        "sample_answer_text": "Mất cân bằng dữ liệu xảy ra khi số lượng mẫu của một lớp trong tập dữ liệu nhỏ hơn đáng kể so với các lớp khác. Các phương pháp xử lý: Lấy mẫu lại (Resampling): Tăng số lượng mẫu của lớp thiểu số (ví dụ, SMOTE), Undersampling: Giảm số lượng mẫu của lớp đa số. Phương pháp dựa trên trọng số (Weight-based methods): Gán trọng số cao cho các mẫu của lớp thiểu số trong quá trình huấn luyện mô hình. Thuật toán đặc biệt (Algorithm-specific methods): Sử dụng các thuật toán được thiết kế để xử lý dữ liệu mất cân bằng (ví dụ, cost-sensitive learning). Lựa chọn phương pháp: Phụ thuộc vào đặc điểm của dữ liệu và thuật toán phân loại được sử dụng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa mất cân bằng dữ liệu",
                "text": "Định nghĩa Mất cân bằng dữ liệu: số lượng mẫu của một lớp nhỏ hơn đáng kể so với các lớp khác.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["số lượng mẫu nhỏ hơn", "lớp thiểu số"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Phương pháp Lấy mẫu lại",
                "text": "Phương pháp Lấy mẫu lại (Resampling): SMOTE, Oversampling, Undersampling.",
                "weight": 3.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["resampling", "smote", "oversampling", "undersampling"], "min_count": 1, "score_per_keyword": 1.0, "max_score_for_condition": 3.0}
                ]
            },
            {
                "id": "Phương pháp dựa trên trọng số",
                "text": "Phương pháp dựa trên trọng số (Weight-based methods): Gán trọng số cao cho lớp thiểu số.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["trọng số", "lớp thiểu số trọng số cao"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            },
            {
                "id": "Thuật toán đặc biệt",
                "text": "Thuật toán đặc biệt (Algorithm-specific methods): cost-sensitive learning.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thuật toán đặc biệt", "cost-sensitive learning"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q69",
        "question": "Cây quyết định có thể xử lý biến liên tục bằng cách tìm các điểm chia (split points).",
        "sample_answer_text": "Cây quyết định có thể xử lý các biến liên tục bằng cách tìm các điểm chia (split points) tốt nhất để phân chia dữ liệu. Tìm điểm chia: Thuật toán sẽ duyệt qua các giá trị có thể có của biến liên tục và đánh giá mức độ phân tách dữ liệu (ví dụ, sử dụng Gini index, hoặc information gain). Ví dụ: Với biến \"tuổi\" (liên tục), cây quyết định có thể tạo ra các nút chia như \"tuổi <= 30\" và \"tuổi > 30\". Lưu ý: Cần xem xét kỹ lưỡng để tránh overfitting khi có quá nhiều điểm chia.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Xử lý biến liên tục",
                "text": "Khả năng xử lý biến liên tục: Cây quyết định xử lý biến liên tục bằng cách tìm các điểm chia (split points).",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["biến liên tục", "điểm chia"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            },
            {
                "id": "Cách tìm điểm chia",
                "text": "Cách tìm điểm chia: Thuật toán duyệt qua các giá trị và đánh giá mức độ phân tách dữ liệu (Gini index, information gain).",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["duyệt giá trị", "phân tách dữ liệu"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            },
            {
                "id": "Ví dụ/Lưu ý cây quyết định",
                "text": "Ví dụ/Lưu ý: ví dụ tuổi (tuổi <= 30, tuổi > 30) hoặc tránh overfitting.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["ví dụ tuổi", "tránh overfitting"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q70",
        "question": "Điều chỉnh siêu tham số trong mô hình cây quyết định.",
        "sample_answer_text": "Siêu tham số của cây quyết định: Độ sâu tối đa, số lượng mẫu tối thiểu trên một lá, số lượng thuộc tính xem xét tại mỗi nút) có ảnh hưởng lớn đến hiệu suất của mô hình. Các chiến lược điều chỉnh: Grid search: Thử tất cả các kết hợp có thể có của siêu tham số trong một phạm vi xác định. Random search: Thử một số lượng ngẫu nhiên các kết hợp siêu tham số. Cross-validation: Đánh giá hiệu suất của mô hình trên nhiều tập dữ liệu khác nhau để chọn ra bộ siêu tham số tốt nhất. Bayesian optimization: Sử dụng các thuật toán tối ưu hóa để tìm kiếm các siêu tham số tốt nhất một cách hiệu quả hơn. Lựa chọn chiến lược: Phụ thuộc vào độ phức tạp của bài toán và tài nguyên tính toán.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các siêu tham số chính",
                "text": "Nêu các siêu tham số chính: độ sâu tối đa, số lượng mẫu tối thiểu trên một lá, số lượng thuộc tính xem xét tại mỗi nút.",
                "weight": 3.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["độ sâu tối đa", "số lượng mẫu tối thiểu trên một lá", "số lượng thuộc tính xem xét tại mỗi nút"], "min_count": 2, "score_per_keyword": 1.5, "max_score_for_condition": 3.0, "partial_score_if_less": [{"count": 1, "score": 1.5}]}
                ]
            },
            {
                "id": "Các chiến lược điều chỉnh siêu tham số",
                "text": "Các chiến lược điều chỉnh: Grid search, Random search, Cross-validation, Bayesian optimization.",
                "weight": 7.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["grid search", "thử tất cả kết hợp"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "AND_KEYWORDS", "keywords": ["random search", "thử ngẫu nhiên"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["cross-validation", "đánh giá trên nhiều tập"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["bayesian optimization", "tối ưu hóa hiệu quả hơn"], "score_if_met": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q71",
        "question": "Khi nào nên sử dụng phương pháp bình quân di động?",
        "sample_answer_text": "Nên sử dụng phương pháp bình quân di động khi: Cần làm mịn chuỗi thời gian và loại bỏ các biến động ngẫu nhiên. Dữ liệu không có xu hướng rõ ràng hoặc tính mùa vụ phức tạp. Cần một phương pháp dự báo đơn giản và nhanh chóng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Làm mịn/loại bỏ biến động",
                "text": "Làm mịn/loại bỏ biến động: cần làm mịn chuỗi thời gian và loại bỏ các biến động ngẫu nhiên.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["làm mịn chuỗi thời gian", "loại bỏ biến động ngẫu nhiên"], "score_if_met": 3.5, "partial_score_per_keyword": 1.75}
                ]
            },
            {
                "id": "Dữ liệu không xu hướng/mùa vụ",
                "text": "Dữ liệu không xu hướng/mùa vụ phức tạp: dữ liệu không có xu hướng rõ ràng hoặc tính mùa vụ phức tạp.",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không xu hướng rõ ràng", "tính mùa vụ phức tạp"], "score_if_met": 3.5}
                ]
            },
            {
                "id": "Phương pháp đơn giản/nhanh chóng",
                "text": "Phương pháp đơn giản/nhanh chóng: cần một phương pháp dự báo đơn giản và nhanh chóng.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["đơn giản", "nhanh chóng"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q72",
        "question": "Khi nào nên sử dụng phương pháp làm mịn mũ?",
        "sample_answer_text": "Nên sử dụng phương pháp làm mịn mũ khi: Cần dự báo ngắn hạn. Dữ liệu có xu hướng hoặc tính mùa vụ. Cần một phương pháp linh hoạt hơn để điều chỉnh trọng số cho các quan sát. Muốn nhấn mạnh các quan sát gần nhất.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Dự báo ngắn hạn",
                "text": "Dự báo ngắn hạn: cần dự báo ngắn hạn.",
                "weight": 2.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dự báo ngắn hạn"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Dữ liệu có xu hướng/mùa vụ",
                "text": "Dữ liệu có xu hướng/mùa vụ: dữ liệu có xu hướng hoặc tính mùa vụ.",
                "weight": 2.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["có xu hướng", "có mùa vụ"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Linh hoạt điều chỉnh trọng số",
                "text": "Linh hoạt điều chỉnh trọng số: cần một phương pháp linh hoạt hơn để điều chỉnh trọng số cho các quan sát.",
                "weight": 2.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["linh hoạt", "điều chỉnh trọng số"], "score_if_met": 2.5, "partial_score_per_keyword": 1.25}
                ]
            },
            {
                "id": "Nhấn mạnh quan sát gần nhất",
                "text": "Nhấn mạnh quan sát gần nhất: muốn nhấn mạnh các quan sát gần nhất.",
                "weight": 2.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["nhấn mạnh quan sát gần nhất", "ưu tiên dữ liệu mới"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q73",
        "question": "Khi nào nên sử dụng mô hình ARIMA?",
        "sample_answer_text": "Nên sử dụng mô hình ARIMA khi: Cần dự báo chuỗi thời gian phức tạp có cả thành phần tự hồi quy (AR) và trung bình trượt (MA). Chuỗi thời gian có hoặc có thể được biến đổi thành dữ liệu dừng. Cần một mô hình mạnh mẽ và có khả năng nắm bắt các mối quan hệ trong dữ liệu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Chuỗi thời gian phức tạp (AR/MA)",
                "text": "Chuỗi thời gian phức tạp với AR và MA: cần dự báo chuỗi thời gian phức tạp có cả thành phần tự hồi quy (AR) và trung bình trượt (MA).",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["chuỗi thời gian phức tạp", "ar", "ma"], "score_if_met": 4.0, "partial_score_per_keyword": 1.33}
                ]
            },
            {
                "id": "Yêu cầu tính dừng",
                "text": "Yêu cầu tính dừng: chuỗi thời gian có hoặc có thể được biến đổi thành dữ liệu dừng.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dữ liệu dừng", "biến đổi thành dừng"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Mô hình mạnh/nắm bắt mối quan hệ",
                "text": "Mô hình mạnh mẽ, nắm bắt mối quan hệ: cần một mô hình mạnh mẽ và có khả năng nắm bắt các mối quan hệ trong dữ liệu.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mô hình mạnh mẽ", "nắm bắt mối quan hệ"], "score_if_met": 3.0}
                ]
            }
        ]
    },
    {
        "id": "Q74",
        "question": "\"Curse of dimensionality\" và ảnh hưởng của nó đến phân cụm.",
        "sample_answer_text": "\"Curse of dimensionality\" đề cập đến việc khi số chiều dữ liệu (số lượng thuộc tính) tăng lên, dữ liệu trở nên thưa thớt hơn, làm giảm hiệu quả của các thuật toán phân cụm. Trong không gian nhiều chiều, khoảng cách giữa các điểm dữ liệu có xu hướng trở nên tương đồng hơn, làm cho việc phân biệt các cụm trở nên khó khăn hơn. Các thuật toán phân cụm dựa trên khoảng cách (ví dụ, k-means) đặc biệt nhạy cảm với hiện tượng này. Giải pháp: Giảm chiều dữ liệu bằng các phương pháp như PCA, lựa chọn thuộc tính (feature selection), hoặc sử dụng các thuật toán phân cụm phù hợp với dữ liệu nhiều chiều.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Curse of dimensionality",
                "text": "Định nghĩa \"Curse of dimensionality\": số chiều dữ liệu tăng lên, dữ liệu trở nên thưa thớt hơn.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["số chiều tăng", "thưa thớt hơn"], "score_if_met": 4.0, "partial_score_per_keyword": 2.0}
                ]
            },
            {
                "id": "Ảnh hưởng đến phân cụm",
                "text": "Ảnh hưởng đến phân cụm: khoảng cách giữa các điểm dữ liệu có xu hướng trở nên tương đồng hơn, khó phân biệt các cụm. Các thuật toán phân cụm dựa trên khoảng cách (ví dụ, k-means) đặc biệt nhạy cảm.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["khoảng cách tương đồng", "khó phân biệt cụm"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["thuật toán dựa trên khoảng cách", "k-means", "nhạy cảm"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66}
                ]
            },
            {
                "id": "Giải pháp Curse of dimensionality",
                "text": "Giải pháp: giảm chiều dữ liệu (PCA, feature selection).",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giảm chiều dữ liệu", "pca", "feature selection"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q75",
        "question": "Thuật toán Random Forest là gì?",
        "sample_answer_text": "Random Forest là một thuật toán ensemble (kết hợp) sử dụng nhiều cây quyết định. Hoạt động: Lấy mẫu bootstrap: Tạo ra nhiều tập dữ liệu con bằng cách lấy mẫu ngẫu nhiên có hoàn lại từ tập dữ liệu gốc. Xây dựng cây quyết định: Huấn luyện một cây quyết định trên mỗi tập dữ liệu con, và chỉ sử dụng một tập con ngẫu nhiên của các thuộc tính. Dự đoán: Tổng hợp kết quả dự đoán từ tất cả các cây quyết định để đưa ra dự đoán cuối cùng. Ưu điểm: Thường cho kết quả chính xác hơn so với cây quyết định đơn lẻ. Giảm overfitting. Có thể xử lý dữ liệu nhiều chiều và dữ liệu có nhiều nhiễu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Random Forest",
                "text": "Định nghĩa Random Forest: thuật toán ensemble (kết hợp) sử dụng nhiều cây quyết định.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["ensemble", "nhiều cây quyết định"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Hoạt động Random Forest",
                "text": "Hoạt động: Lấy mẫu bootstrap (ngẫu nhiên có hoàn lại), Xây dựng cây quyết định trên mỗi tập con (chỉ sử dụng tập con thuộc tính), Tổng hợp kết quả dự đoán.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["bootstrap", "lấy mẫu có hoàn lại"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["xây dựng cây trên tập con", "chọn thuộc tính ngẫu nhiên"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["tổng hợp kết quả", "bỏ phiếu"], "score_if_met": 1.0}
                ]
            },
            {
                "id": "Ưu điểm Random Forest",
                "text": "Ưu điểm: chính xác hơn, giảm overfitting, xử lý dữ liệu nhiều chiều/nhiễu.",
                "weight": 4.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["chính xác hơn", "giảm overfitting", "xử lý dữ liệu nhiều chiều", "xử lý dữ liệu nhiễu"], "min_count": 2, "score_per_keyword": 2.0, "max_score_for_condition": 4.0, "partial_score_if_less": [{"count": 1, "score": 2.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q76",
        "question": "Đánh giá hiệu suất mô hình phân cụm khi không biết nhãn.",
        "sample_answer_text": "Đánh giá mô hình phân cụm khi không biết nhãn thực là một thách thức. Các phương pháp đánh giá: Độ đo nội tại (Internal metrics): Đánh giá dựa trên cấu trúc của các cụm, không cần nhãn. Ví dụ: Silhouette coefficient: Đánh giá mức độ tách biệt giữa các cụm. Davies-Bouldin index: Đánh giá sự tương đồng dựa trên các điểm trong cùng cụm so với các cụm khác. Độ đo tương đối (Relative metrics): So sánh kết quả phân cụm với một cấu trúc cụm tham chiếu. Độ đo ổn định (Stability metrics): Đánh giá sự ổn định của kết quả phân cụm khi có sự thay đổi nhỏ trong dữ liệu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Độ đo nội tại",
                "text": "Độ đo nội tại (Internal metrics): không cần nhãn, Silhouette coefficient (tách biệt giữa các cụm), Davies-Bouldin index (tương đồng trong cụm so với cụm khác).",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["độ đo nội tại", "không cần nhãn"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "AND_KEYWORDS", "keywords": ["silhouette coefficient", "tách biệt giữa các cụm"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "AND_KEYWORDS", "keywords": ["davies-bouldin index", "tương đồng trong cụm so với cụm khác"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Độ đo tương đối",
                "text": "Độ đo tương đối (Relative metrics): so sánh với cấu trúc cụm tham chiếu.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["độ đo tương đối", "cấu trúc cụm tham chiếu"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Độ đo ổn định",
                "text": "Độ đo ổn định (Stability metrics): đánh giá sự ổn định khi dữ liệu thay đổi nhỏ.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["độ đo ổn định", "dữ liệu thay đổi nhỏ"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            }
        ]
    },
    {
        "id": "Q77",
        "question": "Phân tích chuỗi thời gian với dữ liệu bị thiếu.",
        "sample_answer_text": "Dữ liệu chuỗi thời gian bị thiếu là một vấn đề phổ biến trong thực tế. Các thách thức: Gây ảnh hưởng đến tính chính xác của phân tích chuỗi thời gian. Làm gián đoạn các mô hình phân tích. Các phương pháp xử lý: Điền giá trị trung bình/trung vị: Thay thế giá trị bị thiếu bằng giá trị trung bình hoặc trung vị của chuỗi thời gian. Nội suy tuyến tính: Ước tính giá trị bị thiếu dựa trên các giá trị xung quanh. Nội suy đa thức: Ước tính giá trị bị thiếu bằng cách sử dụng đa thức phù hợp. Các mô hình dự báo: Sử dụng các mô hình dự báo chuỗi thời gian để ước tính các giá trị bị thiếu. Lựa chọn phương pháp: Phụ thuộc vào đặc điểm của chuỗi thời gian và mức độ thiếu dữ liệu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Thách thức dữ liệu thiếu",
                "text": "Thách thức của dữ liệu thiếu: ảnh hưởng đến tính chính xác hoặc làm gián đoạn mô hình.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["ảnh hưởng chính xác", "gián đoạn mô hình"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Các phương pháp xử lý dữ liệu thiếu",
                "text": "Các phương pháp xử lý: Điền giá trị trung bình/trung vị, Nội suy tuyến tính, Nội suy đa thức, Các mô hình dự báo.",
                "weight": 8.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["điền trung bình", "điền trung vị", "nội suy tuyến tính", "nội suy đa thức", "mô hình dự báo"], "min_count": 3, "score_per_keyword": 2.0, "max_score_for_condition": 8.0}
                ]
            }
        ]
    },
    {
        "id": "Q78",
        "question": "Mô hình ARIMA và xác định tham số p, d, q.",
        "sample_answer_text": "ARIMA (Autoregressive Integrated Moving Average) là một mô hình phổ biến cho phân tích chuỗi thời gian. Hoạt động: AR (Autoregressive): Mô hình sử dụng các giá trị quá khứ của chuỗi thời gian để dự đoán giá trị hiện tại. I (Integrated): Mô hình loại bỏ tính không dừng (non-stationarity) của chuỗi thời gian bằng cách lấy sai phân (differencing). MA (Moving Average): Mô hình sử dụng các sai số dự báo quá khứ để dự đoán giá trị hiện tại. Tham số p, d, q: p: Bậc của thành phần AR (số lượng độ trễ của chuỗi thời gian được sử dụng trong mô hình). d: Bậc của sai phân (số lần lấy sai phân để làm cho chuỗi thời gian dừng). q: Bậc của thành phần MA (số lượng độ trễ của sai số dự báo được sử dụng trong mô hình). Xác định p, d, q: ACF (Autocorrelation Function) và PACF (Partial Autocorrelation Function): Sử dụng đồ thị ACF và PACF để xác định bậc của các thành phần AR và MA. Grid search: Thử nhiều kết hợp giá trị p, d, q khác nhau và chọn mô hình có AIC (Akaike Information Criterion) hoặc BIC (Bayesian Information Criterion) thấp nhất.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa ARIMA và thành phần",
                "text": "Định nghĩa Mô hình ARIMA: mô hình phổ biến cho phân tích chuỗi thời gian. AR (sử dụng giá trị quá khứ), I (loại bỏ tính không dừng bằng sai phân), MA (sử dụng sai số dự báo quá khứ).",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mô hình dự báo chuỗi thời gian", "kết hợp các thành phần"], "score_if_met": 1.0},
                    {"type": "COUNT_KEYWORDS", "keywords": ["tự hồi quy", "ar", "tích hợp", "i", "trung bình trượt", "ma"], "min_count": 3, "score_per_keyword": 0.67, "max_score_for_condition": 2.0, "partial_score_if_less": [{"count": 2, "score": 1.0}, {"count": 1, "score": 0.5}]}
                ]
            },
            {
                "id": "Giải thích tham số p",
                "text": "Giải thích tham số p: bậc của thành phần AR, số độ trễ của chuỗi thời gian được sử dụng làm biến đầu vào.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["p", "ar", "độ trễ", "biến đầu vào"], "score_if_met": 2.0, "partial_score_per_keyword": 0.5}
                ]
            },
            {
                "id": "Giải thích tham số d",
                "text": "Giải thích tham số d: số lần sai phân (differencing) cần thiết để làm cho chuỗi thời gian trở nên dừng.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["d", "sai phân", "dừng"], "score_if_met": 2.0, "partial_score_per_keyword": 0.67}
                ]
            },
            {
                "id": "Giải thích tham số q",
                "text": "Giải thích tham số q: số lượng các sai số dự báo trễ được sử dụng làm biến đầu vào.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["q", "ma", "sai số dự báo trễ"], "score_if_met": 2.0, "partial_score_per_keyword": 0.67}
                ]
            },
            {
                "id": "Cách xác định tham số ARIMA",
                "text": "Cách xác định p, d, q: ACF và PACF (tìm cut-off), Grid search (AIC/BIC thấp nhất).",
                "weight": 1.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["acf", "pacf", "cut-off"], "score_if_met": 0.5},
                    {"type": "OR_KEYWORDS", "keywords": ["grid search", "aic", "bic"], "score_if_met": 0.5}
                ]
            }
        ]
    },
    {
        "id": "Q79",
        "question": "Hạn chế của ARIMA và các mô hình thay thế cho chuỗi phi tuyến.",
        "sample_answer_text": "Hạn chế của ARIMA: Giả định tuyến tính: ARIMA chỉ phù hợp với chuỗi thời gian có mối quan hệ tuyến tính. Yêu cầu tính dừng: ARIMA yêu cầu chuỗi thời gian phải dừng (có trung bình và phương sai không thay đổi theo thời gian). Các mô hình thay thế cho chuỗi phi tuyến: Mô hình GARCH: Sử dụng để mô hình hóa phương sai thay đổi theo thời gian. Mạng nơ-ron hồi quy (RNN): Có khả năng mô hình hóa các mối quan hệ phi tuyến phức tạp trong chuỗi thời gian. Mô hình SVM: Có thể sử dụng để phân loại hoặc hồi quy trên dữ liệu chuỗi thời gian phi tuyến. Mô hình Prophet: Mô hình dự báo chuỗi thời gian do Facebook phát triển, phù hợp với dữ liệu có tính mùa vụ và xu hướng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Hạn chế ARIMA",
                "text": "Hạn chế của ARIMA: Giả định tuyến tính, Yêu cầu tính dừng.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tuyến tính", "linear"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["tính dừng", "stationary"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Mô hình thay thế phi tuyến",
                "text": "Các mô hình thay thế cho chuỗi phi tuyến: GARCH, Mạng nơ-ron hồi quy (RNN), SVM, Prophet.",
                "weight": 6.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["garch", "mạng nơ-ron hồi quy", "rnn", "svm", "prophet"], "min_count": 2, "score_per_keyword": 3.0, "max_score_for_condition": 6.0, "partial_score_if_less": [{"count": 1, "score": 3.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q80",
        "question": "Xử lý dữ liệu chuỗi thời gian có tính mùa vụ.",
        "sample_answer_text": "Tính mùa vụ là một đặc trưng phổ biến trong dữ liệu chuỗi thời gian (ví dụ, doanh số bán hàng thường tăng vào cuối năm). Các kỹ thuật xử lý: Sai phân mùa vụ (Seasonal differencing): Lấy sai phân giữa các giá trị của chuỗi thời gian tại các khoảng thời gian mùa vụ (ví dụ, lấy sai phân giữa các tháng cùng năm). Mô hình SARIMA (Seasonal ARIMA): Mở rộng mô hình ARIMA để mô hình hóa các thành phần mùa vụ. Phân tách chuỗi thời gian (Time series decomposition): Phân tách chuỗi thời gian thành các thành phần xu hướng, mùa vụ và dư. Các mô hình Prophet hoặc Facebook Prophet: Các mô hình này được thiết kế đặc biệt để xử lý dữ liệu chuỗi thời gian có tính mùa vụ và xu hướng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa tính mùa vụ",
                "text": "Định nghĩa tính mùa vụ: tính mùa vụ là một đặc trưng phổ biến trong dữ liệu chuỗi thời gian.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tính mùa vụ", "chuỗi thời gian"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Các kỹ thuật xử lý tính mùa vụ",
                "text": "Các kỹ thuật xử lý tính mùa vụ: Sai phân mùa vụ, Mô hình SARIMA, Phân tách chuỗi thời gian, Mô hình Prophet.",
                "weight": 8.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["sai phân mùa vụ", "seasonal differencing", "sarima", "phân tách chuỗi thời gian", "time series decomposition", "prophet", "facebook prophet"], "min_count": 3, "score_per_keyword": 2.0, "max_score_for_condition": 8.0}
                ]
            }
        ]
    },
    {
        "id": "Q81",
        "question": "Trình bày một cách cổ điển qui trình kiểm định thống kê, hàm stats.ppf() có ý nghĩa gì ở kiểm định.",
        "sample_answer_text": "Đặt giả thuyết H0 và H1. Chọn mức ý nghĩa alpha. Xác định thống kê kiểm định và phân phối của nó. Tính giá trị quan sát của thống kê kiểm định từ dữ liệu mẫu. Xác định miền bác bỏ. stats.ppf() trả về giá trị tới hạn (critical value) cho phân phối đã cho, tương ứng với xác suất alpha (hoặc 1-alpha/2).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Quy trình kiểm định thống kê",
                "text": "Quy trình kiểm định thống kê: Đặt giả thuyết H0 và H1, Chọn mức ý nghĩa alpha, Xác định thống kê kiểm định và phân phối của nó, Tính giá trị quan sát, Xác định miền bác bỏ.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giả thuyết h0 và h1", "h0", "h1"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["mức ý nghĩa alpha", "chọn alpha"], "score_if_met": 1.5},
                    {"type": "AND_KEYWORDS", "keywords": ["thống kê kiểm định", "phân phối"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "OR_KEYWORDS", "keywords": ["tính giá trị quan sát"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["miền bác bỏ", "rejection region"], "score_if_met": 1.0}
                ]
            },
            {
                "id": "Ý nghĩa hàm stats.ppf()",
                "text": "Ý nghĩa của hàm stats.ppf(): trả về giá trị tới hạn (critical value) cho phân phối đã cho, tương ứng với xác suất alpha (hoặc 1-alpha/2).",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["stats.ppf()", "giá trị tới hạn", "critical value"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["xác suất alpha", "1-alpha/2"], "score_if_met": 1.0}
                ]
            }
        ]
    },
    {
        "id": "Q82",
        "question": "Giải thích về việc định hướng xây dựng mô hình linear regression ở hình Mô hình Linear Regression.",
        "sample_answer_text": "Mô hình Linear Regression tìm mối quan hệ tuyến tính giữa biến phụ thuộc (y) và biến độc lập (x). Nó tìm đường thẳng phù hợp nhất để dự đoán y dựa trên x, tối thiểu hóa tổng bình phương sai số (dự đoán - thực tế).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa và mục tiêu Linear Regression",
                "text": "Định nghĩa và mục tiêu: tìm mối quan hệ tuyến tính giữa biến phụ thuộc (y) và biến độc lập (x) để dự đoán y dựa trên x.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mối quan hệ tuyến tính", "linear relationship"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["biến phụ thuộc", "biến độc lập"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["dự đoán y dựa trên x"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Cách tìm đường thẳng phù hợp Linear Regression",
                "text": "Cách tìm đường thẳng phù hợp nhất: tối thiểu hóa tổng bình phương sai số (dự đoán - thực tế).",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["tối thiểu hóa", "tổng bình phương sai số"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q83",
        "question": "Cây quyết định là gì? Ứng dụng?",
        "sample_answer_text": "Cây quyết định là một mô hình học máy dùng để phân loại và hồi quy. Nó phân chia dữ liệu dựa trên các thuộc tính, tạo thành cấu trúc cây với các nút quyết định và nút lá (đại diện cho lớp hoặc giá trị dự đoán). Ứng dụng: Phân loại khách hàng, dự đoán rủi ro tín dụng,...",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Cây quyết định",
                "text": "Định nghĩa Cây quyết định: mô hình học máy dùng để phân loại và hồi quy. Nó phân chia dữ liệu dựa trên các thuộc tính, tạo thành cấu trúc cây với các nút quyết định và nút lá.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mô hình học máy", "machine learning model"], "score_if_met": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["phân loại", "hồi quy"], "score_if_met": 1.5},
                    {"type": "AND_KEYWORDS", "keywords": ["phân chia dữ liệu", "dựa trên thuộc tính"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "AND_KEYWORDS", "keywords": ["cấu trúc cây", "nút quyết định", "nút lá"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66}
                ]
            },
            {
                "id": "Ứng dụng Cây quyết định",
                "text": "Ứng dụng: Phân loại khách hàng, dự đoán rủi ro tín dụng,...",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["phân loại khách hàng", "dự đoán rủi ro tín dụng", "ứng dụng thực tế"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q84",
        "question": "Phân biệt z-score và z-test.",
        "sample_answer_text": "Z-score: Số đo độ lệch chuẩn của một giá trị so với trung bình. Z-test: Kiểm định giả thuyết về trung bình tổng thể khi biết phương sai tổng thể.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Z-score là gì",
                "text": "Z-score: Số đo độ lệch chuẩn của một giá trị so với trung bình.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["số đo độ lệch chuẩn", "so với trung bình"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5}
                ]
            },
            {
                "id": "Z-test là gì",
                "text": "Z-test: Kiểm định giả thuyết về trung bình tổng thể khi biết phương sai tổng thể.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["kiểm định giả thuyết", "trung bình tổng thể"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["biết phương sai tổng thể", "sigma đã biết"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q85",
        "question": "Phân biệt ratio gain với info gain.",
        "sample_answer_text": "cả hai đều đo lường mức độ thông tin thu được khi phân chia dữ liệu dựa trên một thuộc tính. Info gain: Tính lượng entropy giảm đi sau khi phân chia. Gain ratio: Chuẩn hóa info gain bằng cách chia cho intrinsic information, tránh thiên vị với thuộc tính nhiều giá trị.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điểm chung Gain Ratio/Info Gain",
                "text": "Điểm chung: cả hai đều đo lường mức độ thông tin thu được khi phân chia dữ liệu dựa trên một thuộc tính.",
                "weight": 2.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["đo thông tin thu được", "phân chia dữ liệu"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Info Gain là gì",
                "text": "Info gain: Tính lượng entropy giảm đi sau khi phân chia.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["entropy giảm", "giảm entropy"], "score_if_met": 4.0}
                ]
            },
            {
                "id": "Gain Ratio là gì",
                "text": "Gain ratio: Chuẩn hóa info gain bằng cách chia cho intrinsic information, tránh thiên vị với thuộc tính nhiều giá trị.",
                "weight": 4.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["chuẩn hóa info gain", "chia cho intrinsic information"], "score_if_met": 2.0, "partial_score_per_keyword": 1.0},
                    {"type": "OR_KEYWORDS", "keywords": ["tránh thiên vị", "thuộc tính nhiều giá trị"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q86",
        "question": "Khi nào dùng ARIMA?",
        "sample_answer_text": "ARIMA dùng cho chuỗi thời gian có tính dừng hoặc có thể đưa về tính dừng bằng phép sai phân. Dữ liệu có hiện tượng tự tương quan.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điều kiện tính dừng ARIMA",
                "text": "Chuỗi thời gian dừng hoặc có thể dừng: dùng cho chuỗi thời gian có tính dừng hoặc có thể đưa về tính dừng bằng phép sai phân.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tính dừng", "stationary"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["đưa về dừng", "sai phân", "differencing"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Điều kiện tự tương quan ARIMA",
                "text": "Dữ liệu có hiện tượng tự tương quan.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tự tương quan", "autocorrelation"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q87",
        "question": "Tự hồi quy là gì? Chỉ ra mô hình?",
        "sample_answer_text": "Tự hồi quy là mô hình chuỗi thời gian, giá trị hiện tại phụ thuộc vào các giá trị quá khứ của chính nó.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Tự hồi quy",
                "text": "Định nghĩa Tự hồi quy: mô hình chuỗi thời gian, giá trị hiện tại phụ thuộc vào các giá trị quá khứ của chính nó.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["mô hình chuỗi thời gian", "time series model"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["giá trị hiện tại", "phụ thuộc vào giá trị quá khứ"], "score_if_met": 7.0, "partial_score_per_keyword": 3.5}
                ]
            }
        ]
    },
    {
        "id": "Q88",
        "question": "Nêu cách xây dựng cây quyết định?",
        "sample_answer_text": "Chọn thuộc tính gốc dựa trên độ đo (information gain, gain ratio, gini index). Phân chia dữ liệu theo giá trị thuộc tính gốc. Lặp lại bước 1 và 2 cho các nút con cho đến khi đạt điều kiện dừng",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Bước 1 Xây dựng cây",
                "text": "Bước 1 (Chọn thuộc tính gốc): Chọn thuộc tính gốc dựa trên độ đo (information gain, gain ratio, gini index).",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chọn thuộc tính gốc", "root node"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["độ đo", "information gain", "gain ratio", "gini index"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Bước 2 Xây dựng cây",
                "text": "Bước 2 (Phân chia dữ liệu): Phân chia dữ liệu theo giá trị thuộc tính gốc.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["phân chia dữ liệu", "theo giá trị thuộc tính"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            },
            {
                "id": "Bước 3 Xây dựng cây",
                "text": "Bước 3 (Lặp lại và điều kiện dừng): Lặp lại bước 1 và 2 cho các nút con cho đến khi đạt điều kiện dừng.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["lặp lại", "nút con"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "OR_KEYWORDS", "keywords": ["điều kiện dừng", "stop criterion"], "score_if_met": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q89",
        "question": "So sánh cây quyết định và hồi quy.",
        "sample_answer_text": "Cây quyết định: Xử lý phân loại và hồi quy, dữ liệu rời rạc/liên tục, dễ hiểu. Hồi quy: Tập trung dự đoán giá trị liên tục, giả định quan hệ tuyến tính.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Đặc điểm Cây quyết định",
                "text": "Cây quyết định: Xử lý phân loại và hồi quy, dữ liệu rời rạc/liên tục, dễ hiểu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["phân loại", "hồi quy"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["rời rạc", "liên tục", "dễ hiểu"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Đặc điểm Hồi quy",
                "text": "Hồi quy: Tập trung dự đoán giá trị liên tục, giả định quan hệ tuyến tính.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dự đoán giá trị liên tục", "biến liên tục"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["giả định quan hệ tuyến tính", "linear relationship"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q90",
        "question": "Pandas có các kiểu cấu trúc dữ liệu nào và so sánh các kiểu dữ liệu đó?",
        "sample_answer_text": "Series: Mảng 1 chiều có nhãn. DataFrame: Bảng 2 chiều linh hoạt. Panel: Dữ liệu 3 chiều (ít dùng).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Cấu trúc Series",
                "text": "Series: Mảng 1 chiều có nhãn.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["series", "1 chiều", "nhãn"], "score_if_met": 3.5, "partial_score_per_keyword": 1.16}
                ]
            },
            {
                "id": "Cấu trúc DataFrame",
                "text": "DataFrame: Bảng 2 chiều linh hoạt.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["dataframe", "2 chiều", "linh hoạt"], "score_if_met": 3.5, "partial_score_per_keyword": 1.16}
                ]
            },
            {
                "id": "Cấu trúc Panel",
                "text": "Panel: Dữ liệu 3 chiều (ít dùng).",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["panel", "3 chiều"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q91",
        "question": "So sánh series của pandas và mảng 1 chiều bên numpy?",
        "sample_answer_text": "Giống: Đều lưu trữ dữ liệu 1 chiều. Khác: Series có index, hỗ trợ nhiều kiểu dữ liệu; Numpy array chỉ chứa cùng kiểu dữ liệu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điểm giống Series/Numpy",
                "text": "Giống: Đều lưu trữ dữ liệu 1 chiều.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["lưu trữ 1 chiều", "dữ liệu một chiều"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Khác Series",
                "text": "Khác: Series có index, hỗ trợ nhiều kiểu dữ liệu.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["series có index", "series có nhãn"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["nhiều kiểu dữ liệu", "mixed data types"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Khác Numpy",
                "text": "Numpy array chỉ chứa cùng kiểu dữ liệu.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["numpy array cùng kiểu", "homogeneous data types"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q92",
        "question": "So sánh list và array:",
        "sample_answer_text": "List: Linh hoạt, đa kiểu dữ liệu, kích thước thay đổi. Array: Hiệu quả tính toán, đồng nhất kiểu dữ liệu, kích thước cố định.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Đặc điểm List",
                "text": "List: Linh hoạt, đa kiểu dữ liệu, kích thước thay đổi.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["linh hoạt", "flexible"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["đa kiểu dữ liệu", "mixed types"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["kích thước thay đổi", "resizable"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Đặc điểm Array",
                "text": "Array: Hiệu quả tính toán, đồng nhất kiểu dữ liệu, kích thước cố định.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["hiệu quả tính toán", "performance"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["đồng nhất kiểu", "homogeneous types"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["kích thước cố định", "fixed size"], "score_if_met": 2.0}
                ]
            }
        ]
    },
    {
        "id": "Q93",
        "question": "Giai đoạn tiền xử lý dữ liệu và xử lý cá nhân:",
        "sample_answer_text": "Giai đoạn: Làm sạch (missing values, outliers). Biến đổi (chuẩn hóa, rời rạc hóa). Giảm chiều. Cá nhân: Xử lý missing values, outliers, chuẩn hóa dữ liệu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Giai đoạn tiền xử lý",
                "text": "Các giai đoạn tiền xử lý dữ liệu: Làm sạch (missing values, outliers), Biến đổi (chuẩn hóa, rời rạc hóa), Giảm chiều.",
                "weight": 6.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["làm sạch", "missing values", "outliers"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66},
                    {"type": "AND_KEYWORDS", "keywords": ["biến đổi", "chuẩn hóa", "rời rạc hóa"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66},
                    {"type": "OR_KEYWORDS", "keywords": ["giảm chiều", "dimensionality reduction"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Xử lý cá nhân",
                "text": "Xử lý cá nhân (trong phạm vi tiền xử lý): Xử lý missing values, outliers, chuẩn hóa dữ liệu.",
                "weight": 4.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["xử lý missing values", "điền thiếu", "xử lý outliers", "loại bỏ ngoại lai", "chuẩn hóa dữ liệu", "normalization"], "min_count": 2, "score_per_keyword": 2.0, "max_score_for_condition": 4.0, "partial_score_if_less": [{"count": 1, "score": 2.0}]}
                ]
            }
        ]
    },
    {
        "id": "Q94",
        "question": "Nhận diện outlier và giảm noisy data:",
        "sample_answer_text": "Nhận diện: Boxplot, IQR, Z-score. Giảm noisy: Binning, clustering, hồi quy.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Nhận diện Outlier",
                "text": "Nhận diện Outlier: Boxplot, IQR, Z-score.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["boxplot", "iqr", "z-score"], "min_count": 2, "score_per_keyword": 2.5, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 1, "score": 2.5}]}
                ]
            },
            {
                "id": "Giảm Noisy Data",
                "text": "Giảm Noisy Data: Binning, clustering, hồi quy.",
                "weight": 5.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["binning", "clustering", "hồi quy"], "min_count": 2, "score_per_keyword": 2.5, "max_score_for_condition": 5.0, "partial_score_if_less": [{"count": 1, "score": 2.5}]}
                ]
            }
        ]
    },
    {
        "id": "Q95",
        "question": "Các bước loại bỏ outlier? Phương pháp giữ lại 95% dữ liệu?",
        "sample_answer_text": "Phương pháp IQR (Interquartile Range): Tính IQR bằng cách lấy Q3 trừ Q1. Sau đó xác định “hàng rào” bằng công thức (Q1 - 1.5 * IQR, Q3 + 1.5 * IQR). Giá trị nào nằm ngoài khoảng này sẽ được coi là outlier. Phương pháp Độ lệch chuẩn/Z-score: Tính Z-score cho từng điểm dữ liệu theo công thức: (giá trị - trung bình) / độ lệch chuẩn. Các điểm dữ liệu có Z-score nằm ngoài một ngưỡng nhất định (ví dụ: ±2 hoặc ±3) sẽ được coi là outlier. Phương pháp Clustering: Trong phân cụm dữ liệu, các điểm dữ liệu nằm ngoài các cum thường được coi là outlier. Sau khi xác định các outlier, ta có thể chọn loại bỏ chúng hoặc thay thế bằng các giá trị khác, tùy thuộc vào mục tiêu phân tích. Để giữ lại 95% dữ liệu, các phương pháp sau có thể được sử dụng: Phương pháp Z-score: Khoảng ± 2 độ lệch chuẩn từ giá trị trung bình thường chứa khoảng 95% dữ liệu trong phân phối chuẩn. Các giá trị có Z-score nằm ngoài khoảng từ -2 đến 2 có thể loại bỏ. Phương pháp Percentile: Tính percentile thứ 2.5 (P2.5) và percentile thứ 97.5 (P97.5). Các giá trị nằm ngoài khoảng này có thể được loại bỏ.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các bước loại bỏ Outlier",
                "text": "Các bước loại bỏ Outlier: Phương pháp IQR (Q1, Q3, 1.5*IQR, hàng rào), Phương pháp Z-score (trung bình, độ lệch chuẩn, ngưỡng ±2/±3), Phương pháp Clustering.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["iqr", "q1", "q3", "1.5 * iqr", "hàng rào"], "score_if_met": 2.0, "partial_score_per_keyword": 0.4},
                    {"type": "AND_KEYWORDS", "keywords": ["z-score", "trung bình", "độ lệch chuẩn", "ngưỡng ±2", "±3"], "score_if_met": 2.0, "partial_score_per_keyword": 0.4},
                    {"type": "OR_KEYWORDS", "keywords": ["clustering", "phân cụm"], "score_if_met": 1.0}
                ]
            },
            {
                "id": "Phương pháp giữ lại 95% dữ liệu",
                "text": "Phương pháp giữ lại 95% dữ liệu: Phương pháp Z-score (± 2 độ lệch chuẩn), Phương pháp Percentile (2.5 và 97.5).",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["z-score", "± 2 độ lệch chuẩn", "95%"], "score_if_met": 2.5, "partial_score_per_keyword": 0.83},
                    {"type": "AND_KEYWORDS", "keywords": ["percentile", "2.5", "97.5"], "score_if_met": 2.5, "partial_score_per_keyword": 0.83}
                ]
            }
        ]
    },
    {
        "id": "Q96",
        "question": "Quy trình kiểm định giả thuyết và ý nghĩa:",
        "sample_answer_text": "Quy trình: Đặt giả thuyết. Chọn mức ý nghĩa. Tính thống kê kiểm định. So sánh giá trị tới hạn/p-value. Kết luận. Ý nghĩa: Đưa ra quyết định dựa trên dữ liệu, đánh giá giả thuyết.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Quy trình kiểm định thống kê",
                "text": "Quy trình kiểm định thống kê: Đặt giả thuyết, Chọn mức ý nghĩa, Tính thống kê kiểm định, So sánh giá trị tới hạn/p-value, Kết luận.",
                "weight": 7.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["đặt giả thuyết", "hypothesis formulation"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["mức ý nghĩa alpha", "chọn alpha"], "score_if_met": 1.5},
                    {"type": "AND_KEYWORDS", "keywords": ["thống kê kiểm định", "phân phối"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "OR_KEYWORDS", "keywords": ["tính giá trị quan sát"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["miền bác bỏ", "rejection region"], "score_if_met": 1.0}
                ]
            },
            {
                "id": "Ý nghĩa quy trình kiểm định",
                "text": "Ý nghĩa của quy trình: Đưa ra quyết định dựa trên dữ liệu, đánh giá giả thuyết.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["đưa ra quyết định", "dựa trên dữ liệu"], "score_if_met": 1.5, "partial_score_per_keyword": 0.75},
                    {"type": "OR_KEYWORDS", "keywords": ["đánh giá giả thuyết", "kiểm định giả thuyết"], "score_if_met": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q97",
        "question": "Phân biệt T-test, Z-test, F-test:",
        "sample_answer_text": "Z-test: Biết phương sai tổng thể. T-test: Không biết phương sai tổng thể. F-test: So sánh phương sai hai tổng thể.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điều kiện Z-test",
                "text": "Z-test: Biết phương sai tổng thể.",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["z-test", "biết phương sai tổng thể", "sigma đã biết"], "score_if_met": 3.5}
                ]
            },
            {
                "id": "Điều kiện T-test",
                "text": "T-test: Không biết phương sai tổng thể.",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["t-test", "không biết phương sai tổng thể", "sigma chưa biết"], "score_if_met": 3.5}
                ]
            },
            {
                "id": "Điều kiện F-test",
                "text": "F-test: So sánh phương sai hai tổng thể.",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["f-test", "so sánh phương sai", "hai tổng thể"], "score_if_met": 3.0, "partial_score_per_keyword": 1.0}
                ]
            }
        ]
    },
    {
        "id": "Q98",
        "question": "Công thức tính critical value:",
        "sample_answer_text": "Phụ thuộc loại kiểm định và phân phối thống kê kiểm định.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Phụ thuộc Critical Value",
                "text": "Sự phụ thuộc của Critical Value: Phụ thuộc loại kiểm định và phân phối thống kê kiểm định.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["loại kiểm định", "one-tailed", "two-tailed"], "score_if_met": 5.0},
                    {"type": "OR_KEYWORDS", "keywords": ["phân phối thống kê kiểm định", "distribution"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q99",
        "question": "Hàm stats.norm.ppf() và lý thuyết kiểm định:",
        "sample_answer_text": "Tính giá trị tới hạn cho phân phối chuẩn. Nó liên quan: Xác định miền bác bỏ trong kiểm định giả thuyết.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Chức năng stats.norm.ppf()",
                "text": "Chức năng của stats.norm.ppf(): Tính giá trị tới hạn cho phân phối chuẩn.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giá trị tới hạn", "critical value"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["phân phối chuẩn", "normal distribution"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Liên quan lý thuyết kiểm định",
                "text": "Liên quan đến lý thuyết kiểm định: Xác định miền bác bỏ trong kiểm định giả thuyết.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["xác định miền bác bỏ", "rejection region", "kiểm định giả thuyết"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            }
        ]
    },
    {
        "id": "Q100",
        "question": "Quy trình time-series analysis:",
        "sample_answer_text": "Thu thập dữ liệu. Khám phá dữ liệu (trực quan hóa, thống kê mô tả). Xử lý dữ liệu (missing values, outliers). Xây dựng mô hình. Đánh giá mô hình. Dự báo.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các bước TSA",
                "text": "Các bước của Quy trình Time-Series Analysis: Thu thập dữ liệu, Khám phá dữ liệu (trực quan hóa, thống kê mô tả), Xử lý dữ liệu (missing values, outliers), Xây dựng mô hình, Đánh giá mô hình, Dự báo.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thu thập dữ liệu", "data collection"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["khám phá dữ liệu", "eda", "trực quan hóa", "thống kê mô tả"], "score_if_met": 2.0},
                    {"type": "AND_KEYWORDS", "keywords": ["xử lý dữ liệu", "missing values", "outliers"], "score_if_met": 2.0, "partial_score_per_keyword": 0.66},
                    {"type": "OR_KEYWORDS", "keywords": ["xây dựng mô hình", "model building"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["đánh giá mô hình", "model evaluation"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["dự báo", "forecasting"], "score_if_met": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q101",
        "question": "Quy trình chạy ARIMA:",
        "sample_answer_text": "Kiểm tra tính dừng. Xác định p, d, q. Xây dựng mô hình. Đánh giá. Dự báo.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các bước chạy ARIMA",
                "text": "Các bước của Quy trình chạy ARIMA: Kiểm tra tính dừng, Xác định p, d, q, Xây dựng mô hình, Đánh giá, Dự báo.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["kiểm tra tính dừng", "check stationarity"], "score_if_met": 2.0},
                    {"type": "OR_KEYWORDS", "keywords": ["xác định p d q", "tìm p d q"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["xây dựng mô hình", "model building"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["đánh giá", "evaluation"], "score_if_met": 1.5},
                    {"type": "OR_KEYWORDS", "keywords": ["dự báo", "forecasting"], "score_if_met": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q102",
        "question": "Chỉ số p, d, q trong ARIMA:",
        "sample_answer_text": "p: Số độ trễ tự hồi quy (AR). d: Số lần sai phân để dừng. q: Số độ trễ trung bình trượt (MA).",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Giải thích p ARIMA",
                "text": "Giải thích p: Số độ trễ tự hồi quy (AR).",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["p", "độ trễ", "tự hồi quy", "ar"], "score_if_met": 3.5, "partial_score_per_keyword": 0.875}
                ]
            },
            {
                "id": "Giải thích d ARIMA",
                "text": "Giải thích d: Số lần sai phân để dừng.",
                "weight": 3.5,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["d", "số lần sai phân", "differencing", "để dừng"], "score_if_met": 3.5, "partial_score_per_keyword": 0.875}
                ]
            },
            {
                "id": "Giải thích q ARIMA",
                "text": "Giải thích q: Số độ trễ trung bình trượt (MA).",
                "weight": 3.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["q", "độ trễ", "trung bình trượt", "ma"], "score_if_met": 3.0, "partial_score_per_keyword": 0.75}
                ]
            }
        ]
    },

    {
        "id": "Q103",
        "question": "Khi nào dùng Arima?",
        "sample_answer_text": "Dùng khi chuỗi thời gian dừng hoặc đưa về dừng bằng sai phân. Dữ liệu có hiện tượng tự tương quan.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Điều kiện dùng ARIMA (tính dừng)",
                "text": "Chuỗi thời gian dừng hoặc có thể dừng: dùng khi chuỗi thời gian dừng hoặc đưa về dừng bằng sai phân.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dừng", "stationary"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["sai phân", "differencing"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Điều kiện dùng ARIMA (tự tương quan)",
                "text": "Dữ liệu có hiện tượng tự tương quan.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tự tương quan", "autocorrelation"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q104",
        "question": "Khi nào dùng bình quân di động và hồi quy tuyến tính:",
        "sample_answer_text": "Bình quân di động: Làm mịn, giảm nhiễu, dữ liệu không có xu hướng/mùa vụ phức tạp. Hồi quy tuyến tính: Dự báo khi có xu hướng tuyến tính.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Khi dùng bình quân di động",
                "text": "Bình quân di động: Làm mịn, giảm nhiễu, dữ liệu không có xu hướng/mùa vụ phức tạp.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["làm mịn", "giảm nhiễu"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["không xu hướng", "không mùa vụ", "phức tạp"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Khi dùng hồi quy tuyến tính",
                "text": "Hồi quy tuyến tính: Dự báo khi có xu hướng tuyến tính.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["dự báo", "xu hướng tuyến tính", "linear trend"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            }
        ]
    },
    {
        "id": "Q105",
        "question": "Phân biệt Pandas và Numpy.",
        "sample_answer_text": "Pandas cung cấp cấu trúc dữ liệu linh hoạt (Series, DataFrame) để thao tác và phân tích dữ liệu có nhãn. NumPy tập trung vào tính toán số học với mảng nhiều chiều, hiệu quả cho các phép toán đại số tuyến tính.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Đặc điểm Pandas",
                "text": "Pandas: cấu trúc dữ liệu linh hoạt (Series, DataFrame) để thao tác và phân tích dữ liệu có nhãn.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["series", "dataframe", "cấu trúc linh hoạt"], "score_if_met": 2.5},
                    {"type": "AND_KEYWORDS", "keywords": ["thao tác dữ liệu", "phân tích dữ liệu", "có nhãn"], "score_if_met": 2.5, "partial_score_per_keyword": 0.83}
                ]
            },
            {
                "id": "Đặc điểm NumPy",
                "text": "NumPy: tập trung vào tính toán số học với mảng nhiều chiều, hiệu quả cho các phép toán đại số tuyến tính.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tính toán số học", "mảng nhiều chiều", "multidimensional array"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["đại số tuyến tính", "linear algebra"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q106",
        "question": "Mục tiêu của tiền xử lý dữ liệu là gì?",
        "sample_answer_text": "Mục tiêu của tiền xử lý dữ liệu là cải thiện chất lượng dữ liệu thô/gốc, từ đó cải thiện chất lượng của kết quả phân tích và khai phá dữ liệu. Dữ liệu chất lượng cần đảm bảo tính chính xác, tính hiện hành, tính toàn vẹn, và tính nhất quán.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Mục tiêu cải thiện chất lượng dữ liệu",
                "text": "Cải thiện chất lượng dữ liệu: cải thiện chất lượng dữ liệu thô/gốc.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["cải thiện chất lượng", "làm sạch dữ liệu"], "score_if_met": 5.0}
                ]
            },
            {
                "id": "Mục tiêu cải thiện kết quả phân tích",
                "text": "Cải thiện chất lượng kết quả phân tích/khai phá: cải thiện chất lượng của kết quả phân tích và khai phá dữ liệu.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["cải thiện kết quả phân tích", "cải thiện kết quả khai phá"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q107",
        "question": "Kể tên các bước chính trong quy trình tiền xử lý dữ liệu.",
        "sample_answer_text": "Các bước chính trong quy trình tiền xử lý dữ liệu bao gồm: Làm sạch dữ liệu (data cleaning/cleansing), Tích hợp dữ liệu (data integration), Biến đổi dữ liệu (data transformation), Thu giảm dữ liệu (data reduction)",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các bước tiền xử lý",
                "text": "Các bước chính: Làm sạch dữ liệu, Tích hợp dữ liệu, Biến đổi dữ liệu, Thu giảm dữ liệu.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["làm sạch dữ liệu", "data cleaning"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["tích hợp dữ liệu", "data integration"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["biến đổi dữ liệu", "data transformation"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["thu giảm dữ liệu", "data reduction"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q108",
        "question": "Thế nào là dữ liệu bị thiếu (missing data)? Có những phương pháp nào để xử lý missing data?",
        "sample_answer_text": "Dữ liệu bị thiếu là khi một số thuộc tính của một bản ghi không có giá trị. Các phương pháp xử lý missing data bao gồm: Bỏ qua bản ghi, Điền giá trị bằng một hằng số, Điền bằng giá trị trung bình/trung vị/mode, Điền bằng giá trị phía trên/dưới, Dùng các mô hình dự đoán",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa dữ liệu bị thiếu",
                "text": "Định nghĩa Dữ liệu bị thiếu: một số thuộc tính của một bản ghi không có giá trị.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["không có giá trị", "thiếu giá trị", "null", "nan"], "score_if_met": 4.0}
                ]
            },
            {
                "id": "Các phương pháp xử lý dữ liệu thiếu",
                "text": "Các phương pháp xử lý Missing Data: Bỏ qua bản ghi, Điền giá trị bằng một hằng số, Điền bằng giá trị trung bình/trung vị/mode, Điền bằng giá trị phía trên/dưới, Dùng các mô hình dự đoán.",
                "weight": 6.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["bỏ qua bản ghi", "điền hằng số", "điền trung bình", "điền trung vị", "mode", "điền phía trên/dưới", "dùng mô hình dự đoán"], "min_count": 3, "score_per_keyword": 2.0, "max_score_for_condition": 6.0}
                ]
            }
        ]
    },
    {
        "id": "Q109",
        "question": "Thế nào là dữ liệu nhiễu (noisy data)? Đề xuất các phương pháp để giảm noisy data.",
        "sample_answer_text": "Dữ liệu nhiễu là dữ liệu chứa các lỗi ngẫu nhiên hoặc phương sai trong biến đo. Các phương pháp giảm noisy data bao gồm: Binning (chia dữ liệu thành các khoảng), Regression (hồi quy), Clustering (phân cụm), Phân tích outlier",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa dữ liệu nhiễu",
                "text": "Định nghĩa Dữ liệu nhiễu: dữ liệu chứa các lỗi ngẫu nhiên hoặc phương sai trong biến đo.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["lỗi ngẫu nhiên", "phương sai", "nhiễu", "noisy"], "score_if_met": 4.0}
                ]
            },
            {
                "id": "Các phương pháp giảm dữ liệu nhiễu",
                "text": "Các phương pháp giảm Noisy Data: Binning, Regression, Clustering, Phân tích outlier.",
                "weight": 6.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["binning", "regression", "clustering", "phân tích outlier"], "min_count": 3, "score_per_keyword": 2.0, "max_score_for_condition": 6.0}
                ]
            }
        ]
    },
    {
        "id": "Q110",
        "question": "Làm thế nào để truy xuất dữ liệu từ DataFrame theo cột và dòng?",
        "sample_answer_text": "Trong Pandas, ta có thể lấy dữ liệu theo cột giống như chọn một tiêu đề, còn truy xuất theo dòng thì dựa vào vị trí hoặc tên dòng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Truy xuất theo cột",
                "text": "Truy xuất theo cột: lấy dữ liệu theo cột giống như chọn một tiêu đề.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["theo cột", "tên cột", "tiêu đề"], "score_if_met": 5.0}
                ]
            },
            {
                "id": "Truy xuất theo dòng",
                "text": "Truy xuất theo dòng: dựa vào vị trí hoặc tên dòng.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["theo dòng", "vị trí", "tên dòng", "index", "iloc", "loc"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q111",
        "question": "Hàm apply() trong Pandas dùng để làm gì? Cho ví dụ.",
        "sample_answer_text": "Hàm apply dùng để áp dụng một hàm xử lý cho từng phần tử trong một cột hoặc dòng, ví dụ như nhân đôi, viết hoa hay tính toán gì đó.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Chức năng hàm apply()",
                "text": "Chức năng của hàm apply(): áp dụng một hàm xử lý cho từng phần tử trong một cột hoặc dòng.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["áp dụng hàm", "apply function"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["từng phần tử", "cột", "dòng"], "score_if_met": 3.0, "partial_score_per_keyword": 1.0}
                ]
            },
            {
                "id": "Ví dụ hàm apply()",
                "text": "Cho ví dụ: nhân đôi, viết hoa hay tính toán gì đó.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["nhân đôi", "viết hoa", "tính toán", "ví dụ cụ thể"], "score_if_met": 4.0}
                ]
            }
        ]
    },
    {
        "id": "Q112",
        "question": "Cách tạo một Series từ một list trong Pandas?",
        "sample_answer_text": "Series là một cấu trúc dữ liệu một chiều trong Pandas, giống như một danh sách nhưng có thêm nhãn cho từng phần tử.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa Series",
                "text": "Định nghĩa Series: cấu trúc dữ liệu một chiều có thêm nhãn cho từng phần tử.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["một chiều", "1d"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["nhãn", "index"], "score_if_met": 2.5}
                ]
            },
            {
                "id": "Cách tạo Series từ list",
                "text": "Cách tạo từ list: chuyển list sang Series (ví dụ: pd.Series(my_list)).",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["pd.series(list_name)", "chuyển list sang mảng"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q113",
        "question": "Cách tạo một DataFrame từ một dictionary trong Pandas?",
        "sample_answer_text": "DataFrame là một bảng dữ liệu gồm nhiều cột, và có thể được tạo từ một dictionary, trong đó mỗi khóa là tên cột và mỗi giá trị là danh sách dữ liệu tương ứng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa DataFrame",
                "text": "Định nghĩa DataFrame: bảng dữ liệu gồm nhiều cột.",
                "weight": 4.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["bảng dữ liệu", "nhiều cột", "2 chiều"], "score_if_met": 4.0}
                ]
            },
            {
                "id": "Cách tạo DataFrame từ dict",
                "text": "Cách tạo từ dictionary: có thể được tạo từ một dictionary (ví dụ: pd.DataFrame(my_dict)), trong đó mỗi khóa là tên cột và mỗi giá trị là danh sách dữ liệu tương ứng.",
                "weight": 6.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["pd.dataframe(dict_name)", "chuyển dictionary sang dataframe"], "score_if_met": 3.0},
                    {"type": "AND_KEYWORDS", "keywords": ["khóa là tên cột", "giá trị là danh sách dữ liệu"], "score_if_met": 3.0, "partial_score_per_keyword": 1.5}
                ]
            }
        ]
    },
    {
        "id": "Q114",
        "question": "Cách nối hai DataFrame trong Pandas? Cho ví dụ về concat() và merge().",
        "sample_answer_text": "Ta có thể ghép hai bảng dữ liệu lại với nhau bằng cách nối theo chiều dọc hoặc chiều ngang, tùy mục đích sử dụng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Phương pháp chung nối DataFrame",
                "text": "Phương pháp chung: ghép hai bảng dữ liệu lại với nhau.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["ghép bảng dữ liệu", "nối dataframe"], "score_if_met": 3.0}
                ]
            },
            {
                "id": "Trục nối DataFrame",
                "text": "Nối theo chiều dọc hoặc ngang.",
                "weight": 2.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chiều dọc", "chiều ngang", "axis=0", "axis=1"], "score_if_met": 2.0}
                ]
            },
            {
                "id": "Ví dụ concat/merge",
                "text": "Ví dụ về concat() và merge(): Hàm concat() để nối, hàm merge() để kết hợp.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["concat()", "pd.concat()"], "score_if_met": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["merge()", "pd.merge()"], "score_if_met": 2.5}
                ]
            }
        ]
    },
    {
        "id": "Q115",
        "question": "Phân biệt giữa iloc và loc khi truy xuất dữ liệu trong DataFrame.",
        "sample_answer_text": "iloc là cách truy xuất dữ liệu bằng vị trí, còn loc là truy xuất bằng tên hoặc nhãn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "iloc là gì",
                "text": "iloc: cách truy xuất dữ liệu bằng vị trí.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["iloc", "vị trí", "integer-location"], "score_if_met": 5.0, "partial_score_per_keyword": 1.66}
                ]
            },
            {
                "id": "loc là gì",
                "text": "loc: truy xuất bằng tên hoặc nhãn.",
                "weight": 5.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["loc", "tên", "nhãn", "label-based"], "score_if_met": 5.0, "partial_score_per_keyword": 1.25}
                ]
            }
        ]
    },
    {
        "id": "Q116",
        "question": "Cách tạo mảng NumPy từ list?",
        "sample_answer_text": "Để tạo mảng NumPy từ danh sách, ta chỉ cần chuyển list sang dạng mảng để tiện cho tính toán.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Cách tạo mảng NumPy từ list",
                "text": "Cách tạo: chuyển list sang dạng mảng NumPy (ví dụ: np.array(my_list)).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["np.array()", "chuyển list sang mảng", "from list to array"], "score_if_met": 10.0}
                ]
            }
        ]
    },
    {
        "id": "Q117",
        "question": "Cách truy xuất phần tử trong mảng NumPy?",
        "sample_answer_text": "Việc truy xuất phần tử trong mảng NumPy khá giống với danh sách Python, ta dùng chỉ số để lấy giá trị.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Cách truy xuất phần tử NumPy",
                "text": "Cách truy xuất: dùng chỉ số để lấy giá trị.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chỉ số", "index", "dùng []"], "score_if_met": 10.0}
                ]
            }
        ]
    },
    {
        "id": "Q118",
        "question": "Các phép toán cơ bản trên mảng NumPy?",
        "sample_answer_text": "NumPy hỗ trợ các phép toán cơ bản như cộng, trừ, nhân, chia và áp dụng cho từng phần tử rất nhanh.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Các phép toán cơ bản NumPy",
                "text": "Các phép toán cơ bản: cộng, trừ, nhân, chia.",
                "weight": 10.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["cộng", "trừ", "nhân", "chia"], "min_count": 3, "score_per_keyword": 3.33, "max_score_for_condition": 10.0}
                ]
            }
        ]
    },
    {
        "id": "Q119",
        "question": "Cách thay đổi kích thước mảng NumPy? (reshape)",
        "sample_answer_text": "Khi cần thay đổi số hàng hoặc số cột của mảng, ta có thể thay đổi kích thước mà không làm mất dữ liệu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Thay đổi kích thước NumPy",
                "text": "Cách thay đổi kích thước: thay đổi số hàng hoặc số cột của mảng mà không làm mất dữ liệu.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["thay đổi kích thước", "reshape", "số hàng", "số cột"], "score_if_met": 5.0},
                    {"type": "OR_KEYWORDS", "keywords": ["không mất dữ liệu"], "score_if_met": 5.0}
                ]
            }
        ]
    },
    {
        "id": "Q120",
        "question": "Cách tạo mảng NumPy với các giá trị ngẫu nhiên?",
        "sample_answer_text": "NumPy có thể tạo ra các mảng với giá trị ngẫu nhiên, rất hữu ích trong các bài toán thử nghiệm hoặc huấn luyện mô hình.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Tạo mảng NumPy ngẫu nhiên",
                "text": "Cách tạo: tạo ra các mảng với giá trị ngẫu nhiên (ví dụ: np.random.rand()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["giá trị ngẫu nhiên", "random values", "np.random"], "score_if_met": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q121",
        "question": "Cách sắp xếp mảng NumPy?",
        "sample_answer_text": "Để sắp xếp mảng NumPy, ta có thể sắp xếp tăng dần hoặc giảm dần tùy mục đích.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Sắp xếp mảng NumPy",
                "text": "Cách sắp xếp: sắp xếp tăng dần hoặc giảm dần (ví dụ: np.sort()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "AND_KEYWORDS", "keywords": ["sắp xếp", "sort"], "score_if_met": 5.0, "partial_score_per_keyword": 2.5},
                    {"type": "OR_KEYWORDS", "keywords": ["tăng dần", "giảm dần"], "score_if_met": 5.0}
                ]
            }
        ]
    },

    {
        "id": "Q122",
        "question": "Cách tìm kiếm phần tử trong mảng NumPy?",
        "sample_answer_text": "Khi muốn kiểm tra phần tử nào đó có tồn tại trong mảng hay không, ta có thể thực hiện thao tác tìm kiếm.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Tìm kiếm phần tử NumPy",
                "text": "Cách tìm kiếm: kiểm tra phần tử nào đó có tồn tại trong mảng hoặc thực hiện thao tác tìm kiếm.",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tìm kiếm", "kiểm tra tồn tại", "search", "where", "isin"], "score_if_met": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q123",
        "question": "Cách tính toán thống kê trên mảng NumPy? (mean, std,...)",
        "sample_answer_text": "NumPy cung cấp nhiều hàm để tính trung bình, độ lệch chuẩn và các giá trị thống kê khác một cách nhanh chóng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Tính toán thống kê NumPy",
                "text": "Các hàm thống kê: tính trung bình, độ lệch chuẩn và các giá trị thống kê khác (sum, min, max...).",
                "weight": 10.0,
                "conditions": [
                    {"type": "COUNT_KEYWORDS", "keywords": ["trung bình", "mean", "độ lệch chuẩn", "std", "min", "max", "sum"], "min_count": 3, "score_per_keyword": 3.33, "max_score_for_condition": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q124",
        "question": "Cách tạo mảng NumPy với các giá trị 0 hoặc 1?",
        "sample_answer_text": "Ta có thể tạo mảng chỉ toàn số 0 hoặc toàn số 1, thường dùng để khởi tạo dữ liệu ban đầu.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Tạo mảng NumPy 0/1",
                "text": "Cách tạo: tạo mảng chỉ toàn số 0 hoặc toàn số 1 (ví dụ: np.zeros(), np.ones()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tạo mảng 0", "tạo mảng 1", "np.zeros", "np.ones"], "score_if_met": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q125",
        "question": "Cách tạo mảng NumPy với dãy số cách đều? (arange, linspace)",
        "sample_answer_text": "NumPy cho phép tạo mảng với dãy số tăng đều bằng cách chỉ định khoảng cách giữa các số.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Tạo mảng NumPy dãy số cách đều",
                "text": "Cách tạo: tạo mảng với dãy số tăng đều hoặc cung cấp cú pháp (ví dụ: np.arange(), np.linspace()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["dãy số tăng đều", "arange", "linspace", "np.arange()", "np.linspace()"], "score_if_met": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q126",
        "question": "Cách nối hai mảng NumPy?",
        "sample_answer_text": "Khi muốn ghép hai mảng lại thành một, ta có thể nối chúng theo chiều dọc hoặc chiều ngang.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Nối hai mảng NumPy",
                "text": "Cách nối: nối chúng theo chiều dọc hoặc chiều ngang hoặc cung cấp cú pháp (ví dụ: np.concatenate(), np.vstack(), np.hstack()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["nối mảng", "ghép mảng", "chiều dọc", "chiều ngang", "concatenate", "vstack", "hstack", "np.concatenate()", "np.vstack()", "np.hstack()"], "score_if_met": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q127",
        "question": "Cách chia mảng NumPy thành các mảng con?",
        "sample_answer_text": "NumPy hỗ trợ chia mảng lớn thành nhiều mảng nhỏ, ví dụ như chia theo số cột hoặc số hàng.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Chia mảng NumPy",
                "text": "Cách chia: chia mảng lớn thành nhiều mảng nhỏ hoặc cung cấp cú pháp (ví dụ: np.split(), np.array_split()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["chia mảng", "split", "mảng con", "theo hàng", "theo cột", "np.split()", "np.array_split()"], "score_if_met": 10.0}
                ]
            }
        ]
    },

    {
        "id": "Q128",
        "question": "Cách tính ma trận chuyển vị trong NumPy?",
        "sample_answer_text": "Ma trận chuyển vị là phép đảo hàng thành cột và ngược lại, rất phổ biến trong xử lý ma trận.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Định nghĩa ma trận chuyển vị",
                "text": "Định nghĩa Ma trận chuyển vị: phép đảo hàng thành cột và ngược lại.",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["đảo hàng thành cột", "transpose", "chuyển vị"], "score_if_met": 5.0}
                ]
            },
            {
                "id": "Tính ma trận chuyển vị NumPy",
                "text": "Cách tính trong NumPy: cung cấp cú pháp hoặc mô tả cách tính trong NumPy (ví dụ: .T hoặc np.transpose()).",
                "weight": 5.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": [".t", "np.transpose()"], "score_if_met": 5.0}
                ]
            }
        ]
    },

    {
        "id": "Q129",
        "question": "Phân biệt giữa mảng NumPy và list Python",
        "sample_answer_text": "Mảng NumPy khác với list ở chỗ nó hỗ trợ tính toán nhanh hơn, dùng ít bộ nhớ hơn và có nhiều hàm xử lý mạnh mẽ hơn.",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Hiệu suất NumPy vs List",
                "text": "Hiệu suất: hỗ trợ tính toán nhanh hơn.",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["tính toán nhanh hơn", "hiệu suất cao", "fast calculation", "performance"], "score_if_met": 3.5}
                ]
            },
            {
                "id": "Bộ nhớ NumPy vs List",
                "text": "Bộ nhớ: dùng ít bộ nhớ hơn.",
                "weight": 3.5,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["ít bộ nhớ hơn", "tiết kiệm bộ nhớ", "less memory", "memory efficient"], "score_if_met": 3.5}
                ]
            },
            {
                "id": "Hàm xử lý NumPy vs List",
                "text": "Hàm xử lý: có nhiều hàm xử lý mạnh mẽ hơn.",
                "weight": 3.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["hàm xử lý mạnh mẽ", "nhiều chức năng", "rich functions", "powerful operations"], "score_if_met": 3.0}
                ]
            }
        ]
    },

    {
        "id": "Q130",
        "question": "Cách kiểm tra dữ liệu trùng lặp trong DataFrame?",
        "sample_answer_text": "Sử dụng các phương thức như duplicated() hoặc drop_duplicates().",
        "max_score": 10.0,
        "key_points": [
            {
                "id": "Kiểm tra dữ liệu trùng lặp DataFrame",
                "text": "Phương pháp kiểm tra: Nêu đúng các phương pháp kiểm tra trùng lặp (ví dụ: duplicated(), drop_duplicates()).",
                "weight": 10.0,
                "conditions": [
                    {"type": "OR_KEYWORDS", "keywords": ["duplicated()", "drop_duplicates()", "kiểm tra trùng lặp", "xác định trùng lặp", "phát hiện trùng lặp"], "score_if_met": 10.0}
                ]
            }
        ]
    }
]